# Per cominciare, carichiamo i dati
data <- read.table("data/team_stats.txt", header = T)
head(data)
# Come primo modello consideriamo come esplicative le componenti principali derivanti dai 4 fattori
apply(data[, 5:8], 2, sd)
# La percentuale di palle perse ha una varianza molto diversa dalle altre metriche. E' necessario standardizzare i dati
pca <- prcomp(data[, 5:8], scale. = TRUE)
# Guardiamo la percentuale di varianza spiegata cumulata per capire quante componenti utilizzare
cumsum((pca$sdev ^ 2) / sum(pca$sdev ^ 2))
# 2 componenti principali spiegano una il 74% della varianza totale
X.0 <- pca$x[, c(1, 2)]
# Ora che ho ricavato le esplicative, posso procedere con la costruzione del modello
win.prob.glm.pca <- glm(cbind(data[, 1], data[, 2]) ~ X.0[, 1] + X.0[, 2], family = binomial)
summary(win.prob.glm.pca)
drop1(win.prob.glm.pca)
drop1(win.prob.glm.pca, test = "Chisq")
# Ora che ho ricavato le esplicative, posso procedere con la costruzione del modello
win.prob.glm.pca <- glm(cbind(data[, 1], data[, 2]) ~ X.0[, 1] + X.0[, 2], family = binomial)
summary(win.prob.glm.pca)
drop1(win.prob.glm.pca, test = "Chisq")
# Il coefficiente della seconda variabile canonica è non significativo. Anche l'intercetta risulta non significativa, con il relativo coefficiente sostanzialmente degenere in 0. Aggiorniamo il modello
win.prob.glm.pca <- update(win.prob.glm.pca, . ~ . - X.0[, 2])
summary(win.prob.glm.pca)
# Guardando la devianza residua non siamo soddisfatti dell'adattamento del modello. Il modello corrente, con soli 2 parametri in più rispetto al modello nullo, spiega molto di più di quest'ultimo. Tuttavia viene rifiutata l'ipotesi di adattamento del modello corrente rispetto a quello nullo
# H0: modello nullo   H1: modello corrente
pchisq(win.prob.glm.pca$null.deviance - win.prob.glm.pca$deviance, 1, lower.tail = FALSE)
# H0 : modello corrente  H1: modello saturo
pchisq(win.prob.glm.pca$deviance, 28, lower.tail = FALSE)
# Compariamo i valori osservati con i valori previsti dal modello. L'asse x indica le squadre in ordine alfabetico
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm.pca), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
head(data)
# Costruiamo un altro modello prendendo come esplicative i 4 fattori senza applicare la PCA. La PCA comporta infatti una riduzione della dimensionalità: il modello che ne deriva ha, oltre all'intercetta, 2 parametri (numero di PC considerate) invece che 4. Vediamo se, con più esplicative, il modello si adatta meglio ai dati
win.prob.glm.0 <- glm(cbind(W, L) ~ eFG. + TOV. + ORB. + FTR,
family = binomial, data = data)
summary(win.prob.glm.0)
c(AIC(win.prob.glm.pca, win.prob.glm.0))
# Il modello appena costruito fornisce un adattamento migliore ai dati rispetto a quello visto in precedenza
rbind(c(win.prob.glm.pca$aic, win.prob.glm.0$aic),
c(BIC(win.prob.glm.pca), BIC(win.prob.glm.0)))
# Il modello appena costruito fornisce un adattamento migliore ai dati rispetto a quello visto in precedenza
compare.matrix <- matrix(data = c(win.prob.glm.pca$aic, win.prob.glm.0$aic,
BIC(win.prob.glm.pca), BIC(win.prob.glm.0)), nrow = 2, byrow = TRUE)
compare.matrix
colnames(compare.matrix) <- c("PCA", "Four Factors")
row.names(compare.matrix) <- c("AIC", "BIC")
compare.matrix
# Anche qui confrontiamo valori osservati e predetti
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm.0), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# Compariamo i valori osservati con i valori previsti dal modello. L'asse x indica le squadre in ordine alfabetico
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors (PCA)")
points(1:30, fitted(win.prob.glm.pca), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# Anche qui confrontiamo valori osservati e predetti
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm.0), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
summary(win.prob.glm.0)
# L'adattamento è visibilmente migliorato, tuttavia non siamo soddisfatti rispetto a ciò che otteniamo con il modello saturo
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm.0$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
# Considerata l'importanza che ha il tiro da tre punti nel gioco moderno, costruiamo ora il modello aggiungendo due esplicative: il numero di tiri da tre segnati e il numero di tiri da tre tentati
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
1 - pchisq(44,739, 23)
1 - pchisq(44.739, 23)
# Considerata l'importanza che ha il tiro da tre punti nel basket moderno costruisco un nuovo modello aggiungendo 2 esplicative: numero di tiri da tre segnati e numero di tiri da tre tentati
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix,
data.frame(`Four Factors + 3P` = c(win.prob.glm$aic,
BIC(win.prob.glm))
)
)
compare.matrix
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix,
data.frame(`Four Factors & 3P` = c(win.prob.glm$aic,
BIC(win.prob.glm))
)
)
compare.matrix
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix,
data.frame("Four Factors + 3P" = c(win.prob.glm$aic,
BIC(win.prob.glm))
)
)
compare.matrix
rm(list = ls())
# Per cominciare, carichiamo i dati
data <- read.table("data/team_stats.txt", header = T)
head(data)
# Come primo modello consideriamo come esplicative le componenti principali derivanti dai 4 fattori
apply(data[, 5:8], 2, sd)
# La percentuale di palle perse ha una varianza molto diversa dalle altre metriche. E' necessario standardizzare i dati
pca <- prcomp(data[, 5:8], scale. = TRUE)
# Guardiamo la percentuale di varianza spiegata cumulata per capire quante componenti utilizzare
cumsum((pca$sdev ^ 2) / sum(pca$sdev ^ 2))
# 2 componenti principali spiegano una il 74% della varianza totale
X.0 <- pca$x[, c(1, 2)]
# Ora che ho ricavato le esplicative, posso procedere con la costruzione del modello
win.prob.glm.pca <- glm(cbind(data[, 1], data[, 2]) ~ X.0[, 1] + X.0[, 2], family = binomial)
summary(win.prob.glm.pca)
# Il coefficiente della seconda variabile canonica è non significativo. Anche l'intercetta risulta non significativa, con il relativo coefficiente sostanzialmente degenere in 0. Aggiorniamo il modello
win.prob.glm.pca <- update(win.prob.glm.pca, . ~ . - X.0[, 2])
summary(win.prob.glm.pca)
# Guardando la devianza residua non siamo soddisfatti dell'adattamento del modello. Il modello corrente, con soli 2 parametri in più rispetto al modello nullo, spiega molto di più di quest'ultimo. Tuttavia viene rifiutata l'ipotesi di adattamento del modello corrente rispetto a quello nullo
# H0: modello nullo   H1: modello corrente
pchisq(win.prob.glm.pca$null.deviance - win.prob.glm.pca$deviance,
win.prob.glm.pca$df.null - win.prob.glm.pca$df.residual, lower.tail = FALSE)
# H0 : modello corrente  H1: modello saturo
pchisq(win.prob.glm.pca$deviance, win.prob.glm.pca$df.residual, lower.tail = FALSE)
# Compariamo i valori osservati con i valori previsti dal modello. L'asse x indica le squadre in ordine alfabetico
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors (PCA)")
points(1:30, fitted(win.prob.glm.pca), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# Costruiamo un altro modello prendendo come esplicative i 4 fattori senza applicare la PCA. La PCA comporta infatti una riduzione della dimensionalità: il modello che ne deriva ha, oltre all'intercetta, 2 parametri (numero di PC considerate) invece che 4. Vediamo se, con più esplicative, il modello si adatta meglio ai dati
win.prob.glm.0 <- glm(cbind(W, L) ~ eFG. + TOV. + ORB. + FTR,
family = binomial, data = data)
summary(win.prob.glm.0)
# Il modello appena costruito fornisce un adattamento migliore ai dati rispetto a quello visto in precedenza
compare.matrix <- matrix(data = c(win.prob.glm.pca$aic, win.prob.glm.0$aic,
BIC(win.prob.glm.pca), BIC(win.prob.glm.0)), nrow = 2, byrow = TRUE)
colnames(compare.matrix) <- c("PCA", "4Factors")
row.names(compare.matrix) <- c("AIC", "BIC")
compare.matrix
# Anche qui confrontiamo valori osservati e predetti
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm.0), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# L'adattamento è visibilmente migliorato, tuttavia non siamo soddisfatti rispetto a ciò che otteniamo con il modello saturo
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm.0$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
# Considerata l'importanza che ha il tiro da tre punti nel basket moderno costruisco un nuovo modello aggiungendo 2 esplicative: numero di tiri da tre segnati e numero di tiri da tre tentati
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
# L'adattamento è visibilmente migliorato, tuttavia non siamo soddisfatti rispetto a ciò che otteniamo con il modello saturo
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm.0$deviance, win.prob.glm.0$df.residual, lower.tail = FALSE)
# Considerata l'importanza che ha il tiro da tre punti nel basket moderno costruisco un nuovo modello aggiungendo 2 esplicative: numero di tiri da tre segnati e numero di tiri da tre tentati
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix,
data.frame("4F+3P" = c(win.prob.glm$aic,
BIC(win.prob.glm))
)
)
compare.matrix
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix,
data.frame(4F-3P = c(win.prob.glm$aic,
compare.matrix
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix,
data.frame(4F_3P = c(win.prob.glm$aic,
compare.matrix
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix,
data.frame(4Factors3Point = c(win.prob.glm$aic,
compare.matrix
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix,
data.frame(4Factors3Point = c(win.prob.glm$aic,
compare.matrix
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm))
compare.matrix
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm))
compare.matrix
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm))
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm)))
colnames(compare.matrix) <- c("PCA", "4Factors", "4Factors + 3PTShot")
compare.matrix
# Ciò nonostante, l'adattamento rispetto al modello saturo non è soddisfacente
# H0: modello corrente    H1: modello saturo
pchisq(win.prob.glm$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
summary(glm(cbind(W, L) ~ (.)^2, family = binomial, data = data))
pchisq(13.417, 8, lower.tail = FALSE)
# Proviamo ad aggiungere delle interazioni tra le esplicative
add1(win.prob.glm, (.)^2, tes = "Chisq")
# Proviamo ad aggiungere delle interazioni tra le esplicative
add1(win.prob.glm, (.)^2, test = "Chisq", data = data)
# Considerata l'importanza che ha il tiro da tre punti nel basket moderno costruisco un nuovo modello aggiungendo 2 esplicative: numero di tiri da tre segnati e numero di tiri da tre tentati
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
sort(data[, "eFG."])
# Il coefficiente della percentuale effettiva al tiro è non significativo. Lo rimuoviamo dal modello
win.prob.glm <- update(win.prob.glm, . ~ . - eFG.)
summary(win.prob.glm)
# Il coefficiente della percentuale di rimbalzi offensivi non è significativo. Lo rimuoviamo dal modello
win.prob.glm <- update(win.prob.glm, . ~ . - ORB.)
summary(win.prob.glm)
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm)))
colnames(compare.matrix) <- c("PCA", "4Factors", "4Factors + 3PTShot")
compare.matrix
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm)))
colnames(compare.matrix) <- c("PCA", "4Factors", "4Factors + 3PTShot")
compare.matrix
rm(list = ls())
# Cosa serve per vincere nel basket?
# Per cominciare, carichiamo i dati
data <- read.table("data/team_stats.txt", header = T)
head(data)
# Come primo modello consideriamo come esplicative le componenti principali derivanti dai 4 fattori
apply(data[, 5:8], 2, sd)
# La percentuale di palle perse ha una varianza molto diversa dalle altre metriche. E' necessario standardizzare i dati
pca <- prcomp(data[, 5:8], scale. = TRUE)
# Guardiamo la percentuale di varianza spiegata cumulata per capire quante componenti utilizzare
cumsum((pca$sdev ^ 2) / sum(pca$sdev ^ 2))
# 2 componenti principali spiegano una il 74% della varianza totale
X.0 <- pca$x[, c(1, 2)]
# Ora che ho ricavato le esplicative, posso procedere con la costruzione del modello
win.prob.glm.pca <- glm(cbind(data[, 1], data[, 2]) ~ X.0[, 1] + X.0[, 2], family = binomial)
summary(win.prob.glm.pca)
# Il coefficiente della seconda variabile canonica è non significativo. Anche l'intercetta risulta non significativa, con il relativo coefficiente sostanzialmente degenere in 0. Aggiorniamo il modello
win.prob.glm.pca <- update(win.prob.glm.pca, . ~ . - X.0[, 2])
summary(win.prob.glm.pca)
# Guardando la devianza residua non siamo soddisfatti dell'adattamento del modello. Il modello corrente, con soli 2 parametri in più rispetto al modello nullo, spiega molto di più di quest'ultimo. Tuttavia viene rifiutata l'ipotesi di adattamento del modello corrente rispetto a quello nullo
# H0: modello nullo   H1: modello corrente
pchisq(win.prob.glm.pca$null.deviance - win.prob.glm.pca$deviance,
win.prob.glm.pca$df.null - win.prob.glm.pca$df.residual, lower.tail = FALSE)
# H0 : modello corrente  H1: modello saturo
pchisq(win.prob.glm.pca$deviance, win.prob.glm.pca$df.residual, lower.tail = FALSE)
# Compariamo i valori osservati con i valori previsti dal modello. L'asse x indica le squadre in ordine alfabetico
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors (PCA)")
points(1:30, fitted(win.prob.glm.pca), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# L'adattamento non è sicuramente dei migliori. Il modello, utilizzando solamente due esplicative, deve mediare le percentuali osservate e nei casi estremi (numero di vittorie molto alto o molto basso) dà risultati fuorvianti
# Costruiamo un altro modello prendendo come esplicative i 4 fattori senza applicare la PCA. La PCA comporta infatti una riduzione della dimensionalità: il modello che ne deriva ha, oltre all'intercetta, 2 parametri (numero di PC considerate) invece che 4. Vediamo se, con più esplicative, il modello si adatta meglio ai dati
win.prob.glm.0 <- glm(cbind(W, L) ~ eFG. + TOV. + ORB. + FTR,
family = binomial, data = data)
summary(win.prob.glm.0)
# Il modello appena costruito fornisce un adattamento migliore ai dati rispetto a quello visto in precedenza
compare.matrix <- matrix(data = c(win.prob.glm.pca$aic, win.prob.glm.0$aic,
BIC(win.prob.glm.pca), BIC(win.prob.glm.0)), nrow = 2, byrow = TRUE)
colnames(compare.matrix) <- c("PCA", "4Factors")
row.names(compare.matrix) <- c("AIC", "BIC")
compare.matrix
# Non siamo soddisfatti rispetto a ciò che otteniamo con il modello saturo
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm.0$deviance, win.prob.glm.0$df.residual, lower.tail = FALSE)
# Considerata l'importanza che ha il tiro da tre punti nel basket moderno costruisco un nuovo modello aggiungendo 2 esplicative: numero di tiri da tre segnati e numero di tiri da tre tentati
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
# Il coefficiente della percentuale effettiva al tiro è non significativo. Lo rimuoviamo dal modello
win.prob.glm <- update(win.prob.glm, . ~ . - eFG.)
summary(win.prob.glm)
# Il coefficiente della percentuale di rimbalzi offensivi non è significativo. Lo rimuoviamo dal modello
win.prob.glm <- update(win.prob.glm, . ~ . - ORB.)
summary(win.prob.glm)
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm)))
colnames(compare.matrix) <- c("PCA", "4Factors", "4Factors + 3PTShot")
compare.matrix
# Ciò nonostante, l'adattamento rispetto al modello saturo non è soddisfacente
# H0: modello corrente    H1: modello saturo
pchisq(win.prob.glm$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
# Proviamo ad aggiungere delle interazioni tra le esplicative
add1(win.prob.glm, , test = "Chisq", data = data)
summary(win.prob.glm)
# Ciò nonostante, l'adattamento rispetto al modello saturo non è soddisfacente
# H0: modello corrente    H1: modello saturo
pchisq(win.prob.glm$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
# Proviamo ad aggiungere delle interazioni tra le esplicative
add1(win.prob.glm, ~ . + (.)^2, test = "Chisq", data = data)
setwd("~/Desktop/TERZO ANNO/SDE2/Progetto")
# Per cominciare, carichiamo i dati
data <- read.table("data/team_stats.txt", header = T)
setwd("~/Desktop/TERZO ANNO/SDE2/Progetto_prova")
# Per cominciare, carichiamo i dati
data <- read.table("data/team_stats.txt", header = T)
head(data)
# Per cominciare, carichiamo i dati
data <- read.table("data/team_stats.txt", header = T)
head(data)
# Come primo modello consideriamo come esplicative le componenti principali derivanti dai 4 fattori
apply(data[, 6:9], 2, sd)
# La percentuale di palle perse ha una varianza molto diversa dalle altre metriche. E' necessario standardizzare i dati
pca <- prcomp(data[, 6:9], scale. = TRUE)
# Guardiamo la percentuale di varianza spiegata cumulata per capire quante componenti utilizzare
cumsum((pca$sdev ^ 2) / sum(pca$sdev ^ 2))
# 2 componenti principali spiegano una il 74% della varianza totale
X.0 <- pca$x[, c(1, 2)]
# Ora che ho ricavato le esplicative, posso procedere con la costruzione del modello
win.prob.glm.pca <- glm(cbind(data[, 1], data[, 2]) ~ X.0[, 1] + X.0[, 2], family = binomial)
summary(win.prob.glm.pca)
# Il coefficiente della seconda variabile canonica è non significativo. Anche l'intercetta risulta non significativa, con il relativo coefficiente sostanzialmente degenere in 0. Aggiorniamo il modello
win.prob.glm.pca <- update(win.prob.glm.pca, . ~ . - X.0[, 2])
summary(win.prob.glm.pca)
# Guardando la devianza residua non siamo soddisfatti dell'adattamento del modello. Il modello corrente, con soli 2 parametri in più rispetto al modello nullo, spiega molto di più di quest'ultimo. Tuttavia viene rifiutata l'ipotesi di adattamento del modello corrente rispetto a quello nullo
# H0: modello nullo   H1: modello corrente
pchisq(win.prob.glm.pca$null.deviance - win.prob.glm.pca$deviance,
win.prob.glm.pca$df.null - win.prob.glm.pca$df.residual, lower.tail = FALSE)
# H0 : modello corrente  H1: modello saturo
pchisq(win.prob.glm.pca$deviance, win.prob.glm.pca$df.residual, lower.tail = FALSE)
# Compariamo i valori osservati con i valori previsti dal modello. L'asse x indica le squadre in ordine alfabetico
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors (PCA)")
points(1:30, fitted(win.prob.glm.pca), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# Costruiamo un altro modello prendendo come esplicative i 4 fattori senza applicare la PCA. La PCA comporta infatti una riduzione della dimensionalità: il modello che ne deriva ha, oltre all'intercetta, 2 parametri (numero di PC considerate) invece che 4. Vediamo se, con più esplicative, il modello si adatta meglio ai dati
win.prob.glm.0 <- glm(cbind(W, L) ~ eFG. + TOV. + ORB. + FTR,
family = binomial, data = data)
summary(win.prob.glm.0)
# Il modello appena costruito fornisce un adattamento migliore ai dati rispetto a quello visto in precedenza
compare.matrix <- matrix(data = c(win.prob.glm.pca$aic, win.prob.glm.0$aic,
BIC(win.prob.glm.pca), BIC(win.prob.glm.0)), nrow = 2, byrow = TRUE)
colnames(compare.matrix) <- c("PCA", "4Factors")
row.names(compare.matrix) <- c("AIC", "BIC")
compare.matrix
# Anche qui confrontiamo valori osservati e predetti
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm.0), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# L'adattamento è visibilmente migliorato, tuttavia non siamo soddisfatti rispetto a ciò che otteniamo con il modello saturo
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm.0$deviance, win.prob.glm.0$df.residual, lower.tail = FALSE)
# Considerata l'importanza che hanno il tiro da tre punti e il pace (ritmo di gioco) nel basket moderno costruisco un nuovo modello aggiungendo 3 esplicative: numero di tiri da tre segnati, numero di tiri da tre tentati e possessi per partita
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
# Considerata l'importanza che hanno il tiro da tre punti e il pace (ritmo di gioco) nel basket moderno costruiamo un nuovo modello aggiungendo 3 esplicative: numero di tiri da tre segnati, numero di tiri da tre tentati e possessi per partita
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
# Il coefficiente relativo ai tiri da tre punti tentati a partita è non significativo. Aggiorniamo il modello
win.prob.glm <- update(win.prob.glm, . ~ . - FG3A.GP)
summary(win.prob.glm)
# L'adattamento rispetto ai modelli precedenti è nettamente migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm)))
colnames(compare.matrix) <- c("PCA", "4Factors", "4Factors + 3PTShot")
compare.matrix
pchisq(win.prob.glm.0$deviance, win.prob.glm.0$df.residual, lower.tail = FALSE)
pchisq(win.prob.glm$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
# Il coefficiente relativo ai tiri da tre punti tentati a partita è non significativo. Aggiorniamo il modello
win.prob.glm <- update(win.prob.glm, . ~ . - FG3A.GP)
summary(win.prob.glm)
# L'intercetta risulta non significativa
win.prob.glm <- update(win.prob.glm, . ~ . - 1)
summary(win.prob.glm)
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm)))
colnames(compare.matrix) <- c("PCA", "4Factors", "4Factors + 3PTShot")
compare.matrix
pchisq(win.prob.glm$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm)))
colnames(compare.matrix) <- c("PCA", "4Factors", "4Factors + 3PTShot")
rm(list = ls())
#####
# Cosa serve per vincere nel basket?
# Per cominciare, carichiamo i dati
data <- read.table("data/team_stats.txt", header = T)
head(data)
# Come primo modello consideriamo come esplicative le componenti principali derivanti dai 4 fattori
apply(data[, 6:9], 2, sd)
# La percentuale di palle perse ha una varianza molto diversa dalle altre metriche. E' necessario standardizzare i dati
pca <- prcomp(data[, 6:9], scale. = TRUE)
# Guardiamo la percentuale di varianza spiegata cumulata per capire quante componenti utilizzare
cumsum((pca$sdev ^ 2) / sum(pca$sdev ^ 2))
# 2 componenti principali spiegano una il 74% della varianza totale
X.0 <- pca$x[, c(1, 2)]
# Ora che ho ricavato le esplicative, posso procedere con la costruzione del modello
win.prob.glm.pca <- glm(cbind(data[, 1], data[, 2]) ~ X.0[, 1] + X.0[, 2], family = binomial)
summary(win.prob.glm.pca)
# Il coefficiente della seconda variabile canonica è non significativo. Anche l'intercetta risulta non significativa, con il relativo coefficiente sostanzialmente degenere in 0. Aggiorniamo il modello
win.prob.glm.pca <- update(win.prob.glm.pca, . ~ . - X.0[, 2])
summary(win.prob.glm.pca)
# Guardando la devianza residua non siamo soddisfatti dell'adattamento del modello. Il modello corrente, con soli 2 parametri in più rispetto al modello nullo, spiega molto di più di quest'ultimo. Tuttavia viene rifiutata l'ipotesi di adattamento del modello corrente rispetto a quello nullo
# H0: modello nullo   H1: modello corrente
pchisq(win.prob.glm.pca$null.deviance - win.prob.glm.pca$deviance,
win.prob.glm.pca$df.null - win.prob.glm.pca$df.residual, lower.tail = FALSE)
# H0 : modello corrente  H1: modello saturo
pchisq(win.prob.glm.pca$deviance, win.prob.glm.pca$df.residual, lower.tail = FALSE)
# Compariamo i valori osservati con i valori previsti dal modello. L'asse x indica le squadre in ordine alfabetico
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors (PCA)")
points(1:30, fitted(win.prob.glm.pca), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# L'adattamento non è sicuramente dei migliori. Il modello, utilizzando solamente due esplicative, deve mediare le percentuali osservate e nei casi estremi (numero di vittorie molto alto o molto basso) dà risultati fuorvianti
# Costruiamo un altro modello prendendo come esplicative i 4 fattori senza applicare la PCA. La PCA comporta infatti una riduzione della dimensionalità: il modello che ne deriva ha, oltre all'intercetta, 2 parametri (numero di PC considerate) invece che 4. Vediamo se, con più esplicative, il modello si adatta meglio ai dati
win.prob.glm.0 <- glm(cbind(W, L) ~ eFG. + TOV. + ORB. + FTR,
family = binomial, data = data)
summary(win.prob.glm.0)
# Il modello appena costruito fornisce un adattamento migliore ai dati rispetto a quello visto in precedenza
compare.matrix <- matrix(data = c(win.prob.glm.pca$aic, win.prob.glm.0$aic,
BIC(win.prob.glm.pca), BIC(win.prob.glm.0)), nrow = 2, byrow = TRUE)
colnames(compare.matrix) <- c("PCA", "4Factors")
row.names(compare.matrix) <- c("AIC", "BIC")
compare.matrix
# Anche qui confrontiamo valori osservati e predetti
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm.0), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# L'adattamento è visibilmente migliorato, tuttavia non siamo soddisfatti rispetto a ciò che otteniamo con il modello saturo
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm.0$deviance, win.prob.glm.0$df.residual, lower.tail = FALSE)
# Considerata l'importanza che hanno il tiro da tre punti e il pace (ritmo di gioco) nel basket moderno costruiamo un nuovo modello aggiungendo 3 esplicative: numero di tiri da tre segnati, numero di tiri da tre tentati e possessi per partita
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
# Il coefficiente relativo ai tiri da tre punti tentati a partita è non significativo. Aggiorniamo il modello
win.prob.glm <- update(win.prob.glm, . ~ . - FG3A.GP)
summary(win.prob.glm)
# L'intercetta risulta non significativa
win.prob.glm <- update(win.prob.glm, . ~ . - 1)
summary(win.prob.glm)
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm)))
colnames(compare.matrix) <- c("PCA", "4Factors", "4Factors + 3PTShot")
compare.matrix
pchisq(win.prob.glm$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
# Ciò nonostante, l'adattamento non è soddisfacente
compare.matrix
pchisq(win.prob.glm$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
# Grafico valori previsti e osservati
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# Media della discrepanza tra il numero di vittorie effettivo e il numero di vittorie stimato
mean(abs(residuals(win.prob.glm, type = "response"))
)
# Media della discrepanza tra il numero di vittorie effettivo e il numero di vittorie stimato
mean(abs(residuals(win.prob.glm, type = "response"))) * 82
# Media della discrepanza tra il numero di vittorie effettivo e il numero di vittorie stimato
mean(abs(residuals(win.prob.glm, type = "response"))) * 82
mean(abs(data$W - fitted(win.prob.glm) * 82))
# Metodo alternativo
mean(abs(data$W - fitted(win.prob.glm) * 82))
sd(abs(data$W - fitted(win.prob.glm) * 82))
add1(win.prob.glm, . ~ . + (.)^2)
add1(win.prob.glm, . ~ . + (.)^2, test = "Chisq")
plot(win.prob.glm)
plot(win.prob.glm)[1]
plot(win.prob.glm, which = 1)
# Grafico valori previsti e osservati
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# Metodo alternativo
mean(abs(data$W - fitted(win.prob.glm) * 82))
summary(win.prob.glm)
