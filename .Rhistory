family = quasipoisson(link = "log"), data = Nascar)
summary(nascar.glm0)
nascar.glm.q <- glm(changes ~ drivers + length + laps + length:laps,
family = quasipoisson(link = "log"), data = Nascar)
summary(nascar.glm.q)
hist(stat.pearsons,probability  =TRUE, xlim = c(0, 5000), breaks=2000)
B <- 10000
stat.pearsons <- rep(0,B)
for(i in 1:B){
x <- rnorm(1000,0,3)
y <- rbinom(1000,size = 1,prob = plogis(x))
mod <- glm(y~x,family=binomial)
stat.pearsons[i] <- sum(residuals(mod,type='pearson')^2)
print(i)
}
hist(stat.pearsons,probability  =TRUE, xlim = c(0, 5000), breaks=2000)
abline(v=1000-2)
curve(dchisq(x,998),add=TRUE,col='red')
hist(stat.pearsons / (1000 - 2), prob = TRUE, breaks = 2000, xlim = c(0, 5))
# test di jarque e bera
library(moments)
S <- skewness(stat.pearsons)
K <- kurtosis(stat.pearsons)
m <- length(stat.pearsons)
T.oss <- (m / 6) * (S^2 + ((K - 3) ^ 2 / 4))
pchisq(T.oss, 2, lower.tail = F)
###dati raggruppati
B <- 10000
stat.pearsons.gruppi <- rep(0,B)
for(i in 1:B){
x <- rnorm(1000,0,3)
y <- rbinom(1000,size = 200,prob = plogis(x))#mi=20
mod <- glm(cbind(y,200-y)~x,family=binomial)
stat.pearsons.gruppi[i] <- sum(residuals(mod,type='pearson')^2)
print(i)
}
hist(stat.pearsons.gruppi,probability = TRUE,breaks = 100)
abline(v=1000-2)
curve(dchisq(x,998),add=TRUE,col='red')
hist(stat.pearsons,probability  =TRUE, xlim = c(0, 5000), breaks=2000)
abline(v=1000-2)
curve(dchisq(x,998),add=TRUE,col='red')
z <- c(0.69954, -0.65582, -1.01421)
t(z) %*% Sx.sqrt + mu
Sx.sqrt <- eig.sx$vectors %*% diag(sqrt(eig.sx$values)) %*% t(eig.sx$vectors)
###############
# Esercizio 1 #
###############
data <- read.csv(file.choose(), row.names = 1)
head(data)
dim(data)
# i)
data.num <- data[, 1:8]
apply(data.num, 2, sd)
apply(data.num, 2, range)
# Le variabili considerate presentano variabilità molto diversa e in generale
# codificano valori su scale diverse. E' necessaria quindi una standardizzazione
pc <- prcomp(data.num, scale. = T)
# Percentuale di varianza cumulata spiegata dalle componenti principali
cumsum((pc$sdev ^ 2) / sum(pc$sdev ^ 2))
# Scree plot
plot(pc, type = "l",
main = "Scree plot (dati standardizzati)")
(pc$sdev ^ 2) / sum(pc$sdev ^ 2) >= 1 / 8
# Non riesco a capire se il "gomito" dello scree plot sia nella seconda o terza
# compontente principale; per il criterio della varianza media, dovrei prendere
# solo le prime 2 CP. Per avere almeno il 70 % della varianza spiegata, ne prendo 3
pc$rotation[, 1:3]
# La prima CP dà un buon peso a tutte le variabili fuorchè rent e inst,
# considerate molto meno. La seconda CP riguarda soprattutto l'affitto e il
# possesso dei terreni, la percentuale di forza lavoro impiegata in agricoltura
# e la distribuzione dei terreni. Possiamo affermare che indichi quanto uno stato
# dia importanza all'agricoltura. La terza componente principale descrive
# quasi esclusivamente l'instabilità del paese considerato.
# Con un colore codifico la situazione governativa del paese:
colore <- ifelse(data$demostab == 1, 1, ifelse(data$demoinst == 1, 2, 3))
plot(pc$x[, 1:2], col = colore, pch = 20,
xlab = "PC1 (44.33%)", ylab = "PC2 (21.05%)",
main = "Prime due componenti principali (dati standardizzati)")
# Si nota che mentre i paesi con democrazia stabile sono abbastanza
# "mischiati" con gli altri, i paesi con democrazia stabile appaiono vicini e
# distinti da quelli con dittatura.
# ii)
library(corrplot)
library(CCA)
X1 <- data[, 1:5]
X2 <- data[, 6:8]
cc.paesi <- cc(X1, X2)
rho.hat <- cc.paesi$cor
n <- nrow(data)
p <- ncol(X1)
q <- ncol(X2)
# Test per rho_1 = rho_2 = rho_3 = 0:
-(n - 1 - (p + q + 1) / 2) * log(prod(1 - rho.hat))
qchisq(0.95, p * q) # rifiuto H0
# Si testa la nullità delle ultime due correlazioni canoniche:
-(n - 1 - (p + q + 1) / 2) * log(prod(1 - rho.hat[2:3]))
qchisq(0.95, (p - 1) * (q - 1)) # rifiuto H0
# Si testa la nullità dell'ultima correlazione canonica
-(n - 1 - (p + q + 1) / 2) * log(prod(1 - rho.hat[3]))
qchisq(0.95, (p - 2) * (q - 2)) # accetto H0
rho.hat # i primi due valori mostrano rispettivamente una elevata e buona
# correlazione tra i gruppi di variabili individuati
# Ciò significa che esiste un'elevata correlazione tra l'impegno di un paese
# nell'agricoltura e la sua instabilità governativa.
cc.paesi$scores$corr.X.xscores[, 1]
cc.paesi$scores$corr.Y.xscores[, 1]
# Il numero di persone uccise in seguito a guerre civili o rivoluzioni interne
# è correlato positivamente con la percentuale di forza lavoro impiegata
# in agricoltura e negativamente con il prodotto nazionale pro capite.
cc.paesi$scores$corr.Y.yscores[, 1]
cc.paesi$scores$corr.X.yscores[, 1]
# Si arriva alle stess conclusioni di prima. Dove c'è instabilità governativa
# vi è un prodotto lordo pro capite più basso e più morti per
# battaglie interne allo stato (cosa molto sensata).
# iii)
# Matrice di varianze e covarianze "biased"
S <- var(data.num) * (n - 1) / n
D.sqrt.inv <- diag(1 / sqrt(diag(S)))
H <- diag(n) - rep(1, n) %*% t(rep(1, n)) / n
# Ottengo i dati standardizzati
data.num.std <- H %*% as.matrix(data.num) %*% D.sqrt.inv
# Percentuale di varianza spiegata per un certo numero di cluster:
km1 <- kmeans(data.num.std, centers = 1)
km2 <- kmeans(data.num.std, centers = 2)
km3 <- kmeans(data.num.std, centers = 3)
km4 <- kmeans(data.num.std, centers = 4)
km5 <- kmeans(data.num.std, centers = 5)
explained.var <- c(km1$betweenss / km1$totss,
km2$betweenss / km2$totss,
km3$betweenss / km3$totss,
km4$betweenss / km4$totss,
km5$betweenss / km5$totss)
plot(1:5, explained.var, type = "l", lwd = 2, xlab = "Numero di cluster")
pairs(data.num.std, col = km3$cluster)
pairs(data.num.std, col = km4$cluster)
pairs(data.num.std, col = km2$cluster)
# Sembrano esserci presente 2 gruppi nei dati.
# Creiamo un grafico in cui nell'asse y mettiamo la variabile colore,
# ovvero la situazione politica del paese. Vediamo come la divisione in cluster
# è in accordo con quanto osservato.
library(cluster)
# Distanza euclidea
D <- dist(data.num.std)
# Numero di cluster = 3:
plot(1:n, colore, col = km3$cluster, pch = 20,
xlab = "Nazioni", ylab = "Situazione politica")
legend("right", legend = c("Gruppo 1", "Gruppo 2", "Gruppo 3"),
col = 1:3, pch = 20)
plot(silhouette(km3$cluster, D))
# 4 osservazioni sono in un gruppo che non sia quello più vicino.
# Numero di cluster = 4:
plot(1:n, colore, col = km4$cluster, pch = 20,
xlab = "Nazioni", ylab = "Situazione politica")
legend("right", legend = c("Gruppo 1", "Gruppo 2", "Gruppo 3", "Gruppo 4"),
col = 1:4, pch = 20)
plot(silhouette(km4$cluster, D))
# Tutte le osservazioni sono nei gruppi a cui sono più vicini.
# In entrambi i casi, non c'è corrispondenza tra i gruppi individuati
# dal metodo delle k-medie e la forma governativa osservata nei dati.
# iv)
x.bar <- colMeans(data.num)
S.unb <- var(data.num)
c <- c(92, 2.5, 3.5)
T2.oss <- n * t(x.bar[c(2, 3, 5)] - c) %*% solve(S.unb[c(2, 3, 5), c(2, 3, 5)]) %*% (x.bar[c(2, 3, 5)] - c)
T2.oss <= (n - 1) * 3 * qf(0.95, 3, n - 3) / (n - 3)
# Il punto c appartiene a tale regione di confidenza
# v)
A <- matrix(c(1 / 2, 1 / 3, 0, 0, 4, rep(0, 3),
0, 0, 2, 1, rep(0, 4)),
nrow = 2, byrow = T)
Y <- as.matrix(data.num) %*% t(A)
y.bar <- colMeans(Y)
Sy.unb <- var(Y)
n <- nrow(Y)
p <- ncol(Y)
y.bar[1] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.99, p, n - p) * Sy.unb[1, 1]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.99, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
###############
# Esercizio 2 #
###############
x.bar <- c(1, 5, 2)
Sx <- matrix(c(2, 1, 1,
1, 3, 2,
1, 2, 4),
ncol = 3, byrow = T)
# i)
A <- matrix(c(4, 1, -3, 0, -2, 1), nrow = 2, byrow = T)
b <- matrix(c(0, 2), ncol = 1)
y.bar <- A %*% x.bar + b
Sy <- A %*% Sx %*% t(A)
y.bar
Sy
# ii)
library(mvtnorm)
x <- c(-0.3, 1.7, 0.2)
pmvnorm(upper = x, mean = x.bar, sigma = Sx)
# iii)
# Mi calcolo Sx^(1 / 2)
eig.sx <- eigen(Sx)
Sx.sqrt <- eig.sx$vectors %*% diag(sqrt(eig.sx$values)) %*% t(eig.sx$vectors)
z <- c(0.69954, -0.65582, -1.01421)
t(z) %*% Sx.sqrt + mu
t(z) %*% Sx.sqrt + x.bar
head(data)
dim(data)
# i)
data.num <- data[, 1:8]
apply(data.num, 2, sd)
apply(data.num, 2, range)
# Le variabili considerate presentano variabilità molto diversa e in generale
# codificano valori su scale diverse. E' necessaria quindi una standardizzazione
pc <- prcomp(data.num, scale. = T)
# Percentuale di varianza cumulata spiegata dalle componenti principali
cumsum((pc$sdev ^ 2) / sum(pc$sdev ^ 2))
# Scree plot
plot(pc, type = "l",
main = "Scree plot (dati standardizzati)")
(pc$sdev ^ 2) / sum(pc$sdev ^ 2) >= 1 / 8
# Non riesco a capire se il "gomito" dello scree plot sia nella seconda o terza
# compontente principale; per il criterio della varianza media, dovrei prendere
# solo le prime 2 CP. Per avere almeno il 70 % della varianza spiegata, ne prendo 3
pc$rotation[, 1:3]
# La prima CP dà un buon peso a tutte le variabili fuorchè rent e inst,
# considerate molto meno. La seconda CP riguarda soprattutto l'affitto e il
# possesso dei terreni, la percentuale di forza lavoro impiegata in agricoltura
# e la distribuzione dei terreni. Possiamo affermare che indichi quanto uno stato
# dia importanza all'agricoltura. La terza componente principale descrive
# quasi esclusivamente l'instabilità del paese considerato.
# Con un colore codifico la situazione governativa del paese:
colore <- ifelse(data$demostab == 1, 1, ifelse(data$demoinst == 1, 2, 3))
plot(pc$x[, 1:2], col = colore, pch = 20,
xlab = "PC1 (44.33%)", ylab = "PC2 (21.05%)",
main = "Prime due componenti principali (dati standardizzati)")
# ii)
library(corrplot)
library(CCA)
X1 <- data[, 1:5]
X2 <- data[, 6:8]
cc.paesi <- cc(X1, X2)
rho.hat <- cc.paesi$cor
n <- nrow(data)
p <- ncol(X1)
q <- ncol(X2)
# Test per rho_1 = rho_2 = rho_3 = 0:
-(n - 1 - (p + q + 1) / 2) * log(prod(1 - rho.hat))
qchisq(0.95, p * q) # rifiuto H0
# Si testa la nullità delle ultime due correlazioni canoniche:
-(n - 1 - (p + q + 1) / 2) * log(prod(1 - rho.hat[2:3]))
qchisq(0.95, (p - 1) * (q - 1)) # rifiuto H0
(51 - 1 - (4 + 4 ))
(51 - 1 - (4 + 4) / 2)
(50 - 5)
# Test per rho_1 = rho_2 = rho_3 = 0:
-(n - 1 - (p + q + 1) / 2) * log(prod(1 - rho.hat^2))
qchisq(0.95, p * q) # rifiuto H0
# Si testa la nullità delle ultime due correlazioni canoniche:
-(n - 1 - (p + q + 1) / 2) * log(prod(1 - rho.hat[2:3]^2))
qchisq(0.95, (p - 1) * (q - 1)) # rifiuto H0
rho.hat^2[1] # il primo valore mostra
# iii)
# Matrice di varianze e covarianze "biased"
S <- var(data.num) * (n - 1) / n
D.sqrt.inv <- diag(1 / sqrt(diag(S)))
H <- diag(n) - rep(1, n) %*% t(rep(1, n)) / n
# Ottengo i dati standardizzati
data.num.std <- H %*% as.matrix(data.num) %*% D.sqrt.inv
# Percentuale di varianza spiegata per un certo numero di cluster:
km1 <- kmeans(data.num.std, centers = 1)
km2 <- kmeans(data.num.std, centers = 2)
km3 <- kmeans(data.num.std, centers = 3)
km4 <- kmeans(data.num.std, centers = 4)
km5 <- kmeans(data.num.std, centers = 5)
explained.var <- c(km1$betweenss / km1$totss,
km2$betweenss / km2$totss,
km3$betweenss / km3$totss,
km4$betweenss / km4$totss,
km5$betweenss / km5$totss)
plot(1:5, explained.var, type = "l", lwd = 2, xlab = "Numero di cluster")
pairs(data.num.std, col = km3$cluster)
pairs(data.num.std, col = km4$cluster)
pairs(data.num.std, col = km2$cluster)
# Sembrano esserci presente 2 gruppi nei dati.
# Creiamo un grafico in cui nell'asse y mettiamo la variabile colore,
# ovvero la situazione politica del paese. Vediamo come la divisione in cluster
# è in accordo con quanto osservato.
library(cluster)
# Distanza euclidea
D <- dist(data.num.std)
# Numero di cluster = 3:
plot(1:n, colore, col = km3$cluster, pch = 20,
xlab = "Nazioni", ylab = "Situazione politica")
legend("right", legend = c("Gruppo 1", "Gruppo 2", "Gruppo 3"),
col = 1:3, pch = 20)
plot(silhouette(km3$cluster, D))
# Percentuale di varianza spiegata per un certo numero di cluster:
km1 <- kmeans(data.num.std, centers = 1)
km2 <- kmeans(data.num.std, centers = 2)
km3 <- kmeans(data.num.std, centers = 3)
km4 <- kmeans(data.num.std, centers = 4)
km5 <- kmeans(data.num.std, centers = 5)
explained.var <- c(km1$betweenss / km1$totss,
km2$betweenss / km2$totss,
km3$betweenss / km3$totss,
km4$betweenss / km4$totss,
km5$betweenss / km5$totss)
plot(1:5, explained.var, type = "l", lwd = 2, xlab = "Numero di cluster")
pairs(data.num.std, col = km3$cluster)
pairs(data.num.std, col = km4$cluster)
pairs(data.num.std, col = km2$cluster)
# Sembrano esserci presente 2 gruppi nei dati.
# Creiamo un grafico in cui nell'asse y mettiamo la variabile colore,
# ovvero la situazione politica del paese. Vediamo come la divisione in cluster
# è in accordo con quanto osservato.
library(cluster)
# Distanza euclidea
D <- dist(data.num.std)
# Numero di cluster = 3:
plot(1:n, colore, col = km3$cluster, pch = 20,
xlab = "Nazioni", ylab = "Situazione politica")
legend("right", legend = c("Gruppo 1", "Gruppo 2", "Gruppo 3"),
col = 1:3, pch = 20)
plot(silhouette(km3$cluster, D))
# Una osservazione è in un gruppo che non è quello a cui è più vicino.
# Numero di cluster = 4:
plot(1:n, colore, col = km4$cluster, pch = 20,
xlab = "Nazioni", ylab = "Situazione politica")
legend("right", legend = c("Gruppo 1", "Gruppo 2", "Gruppo 3", "Gruppo 4"),
col = 1:4, pch = 20)
plot(silhouette(km4$cluster, D))
# iv)
x.bar <- colMeans(data.num)
S.unb <- var(data.num)
c <- c(92, 2.5, 3.5)
T2.oss <- n * t(x.bar[c(2, 3, 5)] - c) %*% solve(S.unb[c(2, 3, 5), c(2, 3, 5)]) %*% (x.bar[c(2, 3, 5)] - c)
T2.oss <= (n - 1) * 3 * qf(0.95, 3, n - 3) / (n - 3)
# v)
A <- matrix(c(1 / 2, 1 / 3, 0, 0, 4, rep(0, 3),
0, 0, 2, 1, rep(0, 4)),
nrow = 2, byrow = T)
Y <- as.matrix(data.num) %*% t(A)
y.bar <- colMeans(Y)
Sy.unb <- var(Y)
n <- nrow(Y)
p <- ncol(Y)
y.bar[1] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.99, p, n - p) * Sy.unb[1, 1]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.99, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.95, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
# v)
A <- matrix(c(1 / 2, 1 / 3, 0, 0, 4, rep(0, 3),
0, 0, 2, 1, rep(0, 4)),
nrow = 2, byrow = T)
A
A %*% S.unb %*% t(A)
Sy.unb
y.bar <- colMeans(Y)
y.bar
x.bar
x.bar %*% t(A)
Sy.unb[1, 1]
Sy.unb[2, 2]
n
p
A
colnames(data)
colnames(data.num)
###############
# Esercizio 2 #
###############
x.bar <- c(1, 5, 2)
Sx <- matrix(c(2, 1, 1,
1, 3, 2,
1, 2, 4),
ncol = 3, byrow = T)
# i)
A <- matrix(c(4, 1, -3, 0, -2, 1), nrow = 2, byrow = T)
b <- matrix(c(0, 2), ncol = 1)
y.bar <- A %*% x.bar + b
Sy <- A %*% Sx %*% t(A)
y.bar
Sy
# ii)
library(mvtnorm)
x <- c(-0.3, 1.7, 0.2)
pmvnorm(upper = x, mean = x.bar, sigma = Sx)
# iii)
# Mi calcolo Sx^(1 / 2)
eig.sx <- eigen(Sx)
Sx.sqrt <- eig.sx$vectors %*% diag(sqrt(eig.sx$values)) %*% t(eig.sx$vectors)
z <- c(0.69954, -0.65582, -1.01421)
t(z) %*% Sx.sqrt + x.bar
# v)
A <- matrix(c(1 / 2, 1 / 3, 0, 0, 4, rep(0, 3),
0, 0, 2, 1, rep(0, 4)),
nrow = 2, byrow = T)
Y <- as.matrix(data.num) %*% t(A)
y.bar <- colMeans(Y)
Sy.unb <- var(Y)
n <- nrow(Y)
p <- ncol(Y)
y.bar[1] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.99, p, n - p) * Sy.unb[1, 1]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.99, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.90, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.9999, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.9999999999, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.999999, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.99999, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.999999, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.99998, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
n <- nrow(Y)
p <- ncol(Y)
n
p
y.bar[1] + c(-1, 1) * sqrt((n - 1) * p * qf(0.99, p, n - p) * Sy.unb[1, 1] / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(((n - 1) * p * qf(0.99, p, n - p) * Sy.unb[2, 2]) / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt((n - 1) * p * qf(0.99, p, n - p) * Sy.unb[2, 2] / (n * (n - p)))
y.bar[2] + c(-1, 1) * sqrt(qchisq(0.99, p) * Sy.unb[2, 2] / n)
hist(pnorm(rnorm(100)), prob = T)
hist(pnorm(rnorm(100)), prob = T)
hist(pnorm(rnorm(100)), prob = T)
hist(pnorm(rnorm(100)), prob = T)
hist(pnorm(rnorm(1000)), prob = T)
hist(pnorm(rnorm(1000)), prob = T)
# Per cominciare, carichiamo i dati
data <- read.table("data/team_stats.txt", header = T)
rm(list = ls())
setwd("~/Desktop/TERZO ANNO/SDE2/Progetto_prova")
# Per cominciare, carichiamo i dati
data <- read.table("data/team_stats.txt", header = T)
head(data)
# Franchigie considerate
franchigie <- c("ATL", "BOS", "BKN", "CHA", "CHI", "CLE", "DAL", "DEN", "DET", "GSW",
"HOU", "IND", "LAC", "LAL", "MEM", "MIA", "MIL", "MIN", "NOP", "NYK",
"OKC", "ORL", "PHI", "PHX", "POR", "SAC", "SAS", "TOR", "UTA", "WAS")
# Come primo modello consideriamo come esplicative le componenti principali derivanti dai 4 fattori
apply(data[, 6:9], 2, sd)
# La percentuale di palle perse ha una varianza molto diversa dalle altre metriche. E' necessario standardizzare i dati
pca <- prcomp(data[, 6:9], scale. = TRUE)
# Guardiamo la percentuale di varianza spiegata cumulata per capire quante componenti utilizzare
cumsum((pca$sdev ^ 2) / sum(pca$sdev ^ 2))
# 2 componenti principali spiegano una il 74% della varianza totale
X.0 <- pca$x[, c(1, 2)]
# Ora che ho ricavato le esplicative, posso procedere con la costruzione del modello
win.prob.glm.pca <- glm(cbind(data[, 1], data[, 2]) ~ X.0[, 1] + X.0[, 2], family = binomial)
summary(win.prob.glm.pca)
# Il coefficiente della seconda variabile canonica è non significativo. Anche l'intercetta risulta non significativa, con il relativo coefficiente sostanzialmente degenere in 0. Aggiorniamo il modello
win.prob.glm.pca <- update(win.prob.glm.pca, . ~ . - X.0[, 2])
summary(win.prob.glm.pca)
# Guardando la devianza residua non siamo soddisfatti dell'adattamento del modello. Il modello corrente, con soli 2 parametri in più rispetto al modello nullo, spiega molto di più di quest'ultimo. Tuttavia viene rifiutata l'ipotesi di adattamento del modello corrente rispetto a quello nullo
# H0: modello nullo   H1: modello corrente
pchisq(win.prob.glm.pca$null.deviance - win.prob.glm.pca$deviance,
win.prob.glm.pca$df.null - win.prob.glm.pca$df.residual, lower.tail = FALSE)
# H0 : modello corrente  H1: modello saturo
pchisq(win.prob.glm.pca$deviance, win.prob.glm.pca$df.residual, lower.tail = FALSE)
# Compariamo i valori osservati con i valori previsti dal modello. L'asse x indica le squadre in ordine alfabetico
diff.pca <- data$W - fitted(win.prob.glm.pca) * 82
plot(1:30, diff.pca, type = "h", xlab = "NBA teams", ylab = "W.obs - W.exp",
ylim = c(-25, 20), xaxt = "n", main = "Adattamento modello logit PCA")
abline(h = 0, lty = 2)
axis(1, at = 1:30, labels = franchigie, las = 2, cex.axis = 0.8)
# Costruiamo un altro modello prendendo come esplicative i 4 fattori senza applicare la PCA. La PCA comporta infatti una riduzione della dimensionalità: il modello che ne deriva ha, oltre all'intercetta, 2 parametri (numero di PC considerate) invece che 4. Vediamo se, con più esplicative, il modello si adatta meglio ai dati
win.prob.glm.0 <- glm(cbind(W, L) ~ eFG. + TOV. + ORB. + FTR,
family = binomial, data = data)
summary(win.prob.glm.0)
# Il modello appena costruito fornisce un adattamento migliore ai dati rispetto a quello visto in precedenza
compare.matrix <- matrix(data = c(win.prob.glm.pca$aic, win.prob.glm.0$aic,
BIC(win.prob.glm.pca), BIC(win.prob.glm.0)), nrow = 2, byrow = TRUE)
colnames(compare.matrix) <- c("PCA", "4Factors")
row.names(compare.matrix) <- c("AIC", "BIC")
compare.matrix
# Anche qui confrontiamo valori osservati e predetti
diff.4f <- data$W - fitted(win.prob.glm.0) * 82
plot(1:30, diff.4f, type = "h", xlab = "NBA teams", ylab = "W.obs - W.exp",
ylim = c(-25, 20), xaxt = "n", main = "Adattamento modello logit 4 factors")
abline(h = 0, lty = 2)
axis(1, at = 1:30, labels = franchigie, las = 2, cex.axis = 0.8)
# L'adattamento è visibilmente migliorato, tuttavia non siamo soddisfatti rispetto a ciò che otteniamo con il modello saturo
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm.0$deviance, win.prob.glm.0$df.residual, lower.tail = FALSE)
# Considerata l'importanza che hanno il tiro da tre punti e il pace (ritmo di gioco) nel basket moderno costruiamo un nuovo modello aggiungendo 3 esplicative: numero di tiri da tre segnati, numero di tiri da tre tentati e possessi per partita
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
# Il coefficiente relativo ai tiri da tre punti tentati a partita è non significativo. Aggiorniamo il modello
win.prob.glm <- update(win.prob.glm, . ~ . - FG3A.GP)
summary(win.prob.glm)
# L'intercetta risulta non significativa
win.prob.glm <- update(win.prob.glm, . ~ . - 1)
summary(win.prob.glm)
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm)))
colnames(compare.matrix) <- c("PCA", "4Factors", "4Factors + 3PTShot")
compare.matrix
# Accettiamo l'ipotesi nulla ad un livello di significatività del 5%
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
# Grafico valori previsti e osservati
diff.4f.mod <- data$W - fitted(win.prob.glm) * 82
plot(1:30, diff.4f.mod, type = "h", xlab = "NBA teams", ylab = "W.obs - W.exp",
ylim = c(-25, 20), xaxt = "n", main = "Adattamento modello logit 4 factors + pace + 3P shot")
abline(h = 0, lty = 2)
axis(1, at = 1:30, labels = franchigie, las = 2, cex.axis = 0.8)
# Media della discrepanza tra il numero di vittorie effettivo e il numero di vittorie stimato
mean(abs(residuals(win.prob.glm, type = "response"))) * 82
# Metodo alternativo
mean(abs(data$W - fitted(win.prob.glm) * 82))
sd(abs(data$W - fitted(win.prob.glm) * 82))
# Ciò significa che in media sbaglio la previsione delle vittorie di 4 unità
# Non vi è struttura di dipendenza tra i valori predetti e i residui
plot(win.prob.glm, which = 1)
# Le possibili interazioni aggiuntive risultano non significative
add1(win.prob.glm, . ~ . + (.)^2, test = "Chisq")
rm(list = ls())
