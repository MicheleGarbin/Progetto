student.glmer <- glmer(y ~ subject + (1 | item), data = Testingresso,
family = binomial, nAGQ = 70)
summary(student.glmer)
?Testingresso
student.glmer <- glmer(y ~ item + (1 | subject), data = Testingresso,
family = binomial, nAGQ = 70)
summary(student.glmer)
student.glmer <- glmer(y ~ subject + item + (1 | subject), data = Testingresso,
family = binomial, nAGQ = 70)
summary(student.glmer)
# (b) Si specifichi un modello con intercetta casuale analogo al modello
# (7.23) per la probabilità di risposta corretta dello studente i -esimo
# alla domanda j -esima
library(lme4)
student.glmer <- glmer(y ~ item + (1 | subject), data = Testingresso,
family = binomial, nAGQ = 70)
summary(student.glmer)
# la correttezza o meno della risposta di un certo studente
library(lattice)
xyplot(fitted(student.glmer) ~ subject | as.factor(item), data = Testingresso)
xyplot(fitted(student.glmer) ~ item | as.factor(subject), data = Testingresso)
# la correttezza o meno della risposta di un certo studente
student.glmer.0 <- update(student.glmer, . ~ .  - item)
summary(student.glmer.0)
# (a) Come analisi preliminare si valutino le percentuali di risposte
# corrette per soggetto e per domanda
prop.table(table(Testingresso$subject, Testingresso$y), 1)[, 2] * 100
fitted(student.glmer)
fitted(student.glmer.0)
unique(fitted(student.glmer.0))
sort(unique(fitted(student.glmer.0)))
library(lattice)
xyplot(fitted(student.glmer.0) ~ item | as.factor(subject), data = Testingresso)
# (b) Si specifichi un modello con intercetta casuale analogo al modello
# (7.23) per la probabilità di risposta corretta dello studente i -esimo
# alla domanda j -esima
# (c) Si stimi il modello definito al punto precedente e si
# interpretino i risultati
library(lme4)
student.glmer <- glmer(y ~ item + (1 | subject), data = Testingresso,
family = binomial, nAGQ = 70)
summary(student.glmer) # la domanda risulta non significativa nel prevedere
student.glmer <- glmer(y ~ item + (1 | subject), data = Testingresso,
family = binomial, nAGQ = 70)
summary(student.glmer) # la domanda risulta non significativa nel prevedere
xyplot(fitted(student.glmer) ~ item | as.factor(subject), data = Testingresso)
# dati osservati
xyplot(y ~ item | as.factor(subject), data = Testingresso)
summary(glmer(y ~ item * subject + (1 | subject), data = Testingresso,
family = binomial, nAGQ = 70))
# (d) Si desidera verificare l’ipotesi che le domande abbiano uguale difficoltà.
# Si espliciti l’ipotesi nulla corrispondente e si ottenga il test del
# rapporto di verosimiglianza
# Ciò significa chiedere se il coefficiente della variabile item sia significativo
W <- 2 * (logLik(student.glmer) - logLik(student.glmer.0))
student.glmer$residuals
?glmer
summary(student.glmer) # la domanda risulta non significativa nel prevedere
summary(student.glmer.0)
pchisq(W, 1, lower.tail = FALSE)
anova(student.glmer.0, student.glmer)
pchisq(W, 1, lower.tail = FALSE) # accetto H0
rm(list=ls())
library(MASS)
head(epil)
str(epil)
epil$V4 <- as.factor(epil$V4)
str(Testingresso)
Testingresso$subject <- as.factor(Testingresso$subject)
Testingresso$item <- as.factor(Testingresso$item)
# (a) Come analisi preliminare si valutino le percentuali di risposte
# corrette per soggetto e per domanda
prop.table(table(Testingresso$subject, Testingresso$y), 1)[, 2] * 100
prop.table(table(Testingresso$item, Testingresso$y), 1)[, 2] * 100
# (b) Si specifichi un modello con intercetta casuale analogo al modello
# (7.23) per la probabilità di risposta corretta dello studente i -esimo
# alla domanda j -esima
# (c) Si stimi il modello definito al punto precedente e si
# interpretino i risultati
library(lme4)
student.glmer <- glmer(y ~ item + (1 | subject), data = Testingresso,
family = binomial, nAGQ = 70)
summary(student.glmer) # la domanda risulta non significativa nel prevedere
# dati previsti dal modello
xyplot(fitted(student.glmer) ~ item | as.factor(subject), data = Testingresso)
# dati osservati
xyplot(y ~ item | as.factor(subject), data = Testingresso)
# (d) Si desidera verificare l’ipotesi che le domande abbiano uguale difficoltà.
# Si espliciti l’ipotesi nulla corrispondente e si ottenga il test del
# rapporto di verosimiglianza
# Ciò significa chiedere se il coefficiente della variabile item sia significativo
student.glmer.0 <- update(student.glmer, . ~ . - item)
W <- 2 * (logLik(student.glmer) - logLik(student.glmer.0))
pchisq(W, 1, lower.tail = FALSE) # accetto H0
anova(student.glmer.0, student.glmer)
pchisq(W, 9, lower.tail = FALSE) # accetto H0
anova(student.glmer.0, student.glmer)
summary(student.glmer,0)
summary(student.glmer.0)
summary(student.glmer)
# (d) Si desidera verificare l’ipotesi che le domande abbiano uguale difficoltà.
# Si espliciti l’ipotesi nulla corrispondente e si ottenga il test del
# rapporto di verosimiglianza
# Ciò significa chiedere se il coefficiente della variabile item sia significativo
student.glmer.0 <- update(student.glmer, . ~ . - item)
W <- 2 * (logLik(student.glmer) - logLik(student.glmer.0))
pchisq(W, 9, lower.tail = FALSE) # accetto H0
anova(student.glmer.0, student.glmer)
rm(list=ls())
library(MASS)
head(epil)
str(epil)
epil$V4 <- as.factor(epil$V4)
epil$subject <- as.factor(epil$subject)
library(lattice)
xyplot(y ~ period | subject, group = trt,
data = epil, cex = 0.5,par.settings =
list(superpose.symbol = list(pch = c(1, 3, 20))),
as.table = T, auto.key = list(points = T, columns = 3))
epil[epil$subject=='49',] #osservazioni decisamente anomala
mod1 <- glm(y ~ lage + V4 + lbase + trt +lbase:trt,family = poisson(link='log'),data = epil)
summary(mod1)
mean(epil$y)
var(epil$y)
anova(student.glmer.0, student.glmer)
# I dati nel data frame Testingresso si riferiscono al test d’ingresso ai
# corsi di laurea in Scienze Statistiche dell’Università di Padova per l’anno
# accademico 2014/2015. In particolare, sono riportate le risposte di n = 63
# candidati (subject) a m = 10 domande di comprensione di un testo (item).
# La variabile risposta (y) assume valore 1 se la risposta è
# corretta e 0 altrimenti
head(Testingresso)
str(Testingresso)
Testingresso$subject <- as.factor(Testingresso$subject)
Testingresso$item <- as.factor(Testingresso$item)
# (a) Come analisi preliminare si valutino le percentuali di risposte
# corrette per soggetto e per domanda
prop.table(table(Testingresso$subject, Testingresso$y), 1)[, 2] * 100
prop.table(table(Testingresso$item, Testingresso$y), 1)[, 2] * 100
# (b) Si specifichi un modello con intercetta casuale analogo al modello
# (7.23) per la probabilità di risposta corretta dello studente i -esimo
# alla domanda j -esima
# (c) Si stimi il modello definito al punto precedente e si
# interpretino i risultati
library(lme4)
student.glmer <- glmer(y ~ item + (1 | subject), data = Testingresso,
family = binomial, nAGQ = 70)
summary(student.glmer)
# dati previsti dal modello
xyplot(fitted(student.glmer) ~ item | as.factor(subject), data = Testingresso)
# dati osservati
xyplot(y ~ item | as.factor(subject), data = Testingresso)
# (d) Si desidera verificare l’ipotesi che le domande abbiano uguale difficoltà.
# Si espliciti l’ipotesi nulla corrispondente e si ottenga il test del
# rapporto di verosimiglianza
# Ciò significa chiedere se il coefficiente della variabile item sia significativo
student.glmer.0 <- update(student.glmer, . ~ . - item)
W <- 2 * (logLik(student.glmer) - logLik(student.glmer.0))
pchisq(W, 9, lower.tail = FALSE) # rifiuto H0
anova(student.glmer.0, student.glmer)
anova(student.glmer.0, student.glmer, test = "Chisq")
student.glmer$deviance
#in generale sembra avere un effetto benefico:
mean(exp(-0.34588 + 0.5614*epil$lbase) < 1)
mean(epil$y<5)
mod.rid <- update(mod1,.~.-lbase:trt - lage)
summary(mod.rid)
pchisq(mod.rid$deviance - mod1$deviance,df = 2,lower.tail = FALSE)
anova(mod.rid,mod1,test = 'Chisq')
mod.rid$deviance - mod1$deviance
W
anova(student.glmer.0, student.glmer)
library(gee)
mod.gee1 <- gee(y ~ lage + period+ lbase + trt +lbase:trt,id = subject,
data = epil,family = poisson,corstr = 'exchangeable')
summary(mod.gee1)
mod.gee2 <- gee(y ~ lage + period + lbase + trt +lbase:trt,id = subject,
data = epil,family = poisson,corstr = 'AR-M',Mv = 1)
summary(mod.gee2)
pnorm(-1.942919)
summary(mod.gee1)
summary(mod1)
library(MASS)
mod.nb <- glm.nb(mod1$formula,data = epil)
summary(mod.nb)
mod.nb <- glm.nb(y ~ lage + lbase + trt + lbase:trt,data = epil)
summary(mod.nb)
dim(epil)
unique(epil$subject)
library(MASS)
mod.nb <- glm.nb(mod1$formula,data = epil)
summary(mod.nb)
mod.nb <- glm.nb(y ~ lage + lbase + trt + lbase:trt,data = epil)
summary(mod.nb)
library(gee)
mod.gee1 <- gee(y ~ lage + period+ lbase + trt +lbase:trt,id = subject,
data = epil,family = poisson,corstr = 'exchangeable')
summary(mod.gee1)
mod.nb <- glm.nb(y ~ lage + lbase + trt + lbase:trt,data = epil)
summary(mod.nb)
mod.gee1 <- gee(y ~ lage + period+ lbase + trt +lbase:trt,id = subject,
data = epil,family = poisson,corstr = 'exchangeable')
summary(mod.gee1)
mod.gee2 <- gee(y ~ lage + period + lbase + trt +lbase:trt,id = subject,
data = epil,family = poisson,corstr = 'AR-M',Mv = 1)
summary(mod.gee2)
pnorm(-1.942919)
student.glmer <- glmer(y ~ item + (1 | subject), data = Testingresso,
family = binomial, nAGQ = 70)
summary(student.glmer)
par(mfrow = c(1, 2))
# dati previsti dal modello
xyplot(fitted(student.glmer) ~ item | as.factor(subject), data = Testingresso)
# dati osservati
xyplot(y ~ item | as.factor(subject), data = Testingresso)
par(mfrow = c(1, 1))
par(mfrow = c(1, 2))
# dati previsti dal modello
xyplot(fitted(student.glmer) ~ item | as.factor(subject), data = Testingresso)
# dati osservati
xyplot(y ~ item | as.factor(subject), data = Testingresso)
# dati previsti dal modello
xyplot(fitted(student.glmer) ~ item | as.factor(subject), data = Testingresso)
# dati osservati
xyplot(y ~ item | as.factor(subject), data = Testingresso)
summary(student.glmer)
# (a) Come analisi preliminare si valutino le percentuali di risposte
# corrette per soggetto e per domanda
prop.table(table(Testingresso$subject, Testingresso$y), 1)[, 2] * 100
prop.table(table(Testingresso$item, Testingresso$y), 1)[, 2] * 100
# confronto risposte corrette attese per domanda con quelle osservate
cbind(prop.table(table(Testingresso$item, fitted(student.glmer)), 1)[, 2] * 100, prop.table(table(Testingresso$item, Testingresso$y), 1)[, 2] * 100)
dim(fitted(student.glmer))
length(fitted(student.glmer))
table(Testingresso$item, fitted(student.glmer))
cbind(prop.table(table(Testingresso$item, freq.exp), 1)[, 2] * 100, prop.table(table(Testingresso$item, Testingresso$y), 1)[, 2] * 100)
# confronto risposte corrette attese per domanda con quelle osservate
freq.exp <- ifelse(fitted(student.glmer) > 0.5, 1, 0)
cbind(prop.table(table(Testingresso$item, freq.exp), 1)[, 2] * 100, prop.table(table(Testingresso$item, Testingresso$y), 1)[, 2] * 100)
# le percentuali attese e osservate differiscono di un 10 per cento per
# quasi tutte le domande
# confronto percentuale di risposte corrette per soccetto attese vs osservate
cbind(prop.table(table(Testingresso$subject, freq.exp), 1)[, 2] * 100, prop.table(table(Testingresso$subject, Testingresso$y), 1)[, 2] * 100)
setwd("~/Desktop/TERZO ANNO/SDE2/Progetto_prova")
# Per cominciare, carichiamo i dati
data <- read.table("data/team_stats.txt", header = T)
head(data)
# Come primo modello consideriamo come esplicative le componenti principali derivanti dai 4 fattori
apply(data[, 6:9], 2, sd)
# La percentuale di palle perse ha una varianza molto diversa dalle altre metriche. E' necessario standardizzare i dati
pca <- prcomp(data[, 6:9], scale. = TRUE)
# Guardiamo la percentuale di varianza spiegata cumulata per capire quante componenti utilizzare
cumsum((pca$sdev ^ 2) / sum(pca$sdev ^ 2))
# 2 componenti principali spiegano una il 74% della varianza totale
X.0 <- pca$x[, c(1, 2)]
# Ora che ho ricavato le esplicative, posso procedere con la costruzione del modello
win.prob.glm.pca <- glm(cbind(data[, 1], data[, 2]) ~ X.0[, 1] + X.0[, 2], family = binomial)
summary(win.prob.glm.pca)
# Il coefficiente della seconda variabile canonica è non significativo. Anche l'intercetta risulta non significativa, con il relativo coefficiente sostanzialmente degenere in 0. Aggiorniamo il modello
win.prob.glm.pca <- update(win.prob.glm.pca, . ~ . - X.0[, 2])
summary(win.prob.glm.pca)
summary(win.prob.glm.pca)
# Guardando la devianza residua non siamo soddisfatti dell'adattamento del modello. Il modello corrente, con soli 2 parametri in più rispetto al modello nullo, spiega molto di più di quest'ultimo. Tuttavia viene rifiutata l'ipotesi di adattamento del modello corrente rispetto a quello nullo
# H0: modello nullo   H1: modello corrente
pchisq(win.prob.glm.pca$null.deviance - win.prob.glm.pca$deviance,
win.prob.glm.pca$df.null - win.prob.glm.pca$df.residual, lower.tail = FALSE)
# H0 : modello corrente  H1: modello saturo
pchisq(win.prob.glm.pca$deviance, win.prob.glm.pca$df.residual, lower.tail = FALSE)
# Compariamo i valori osservati con i valori previsti dal modello. L'asse x indica le squadre in ordine alfabetico
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors (PCA)")
points(1:30, fitted(win.prob.glm.pca), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# Costruiamo un altro modello prendendo come esplicative i 4 fattori senza applicare la PCA. La PCA comporta infatti una riduzione della dimensionalità: il modello che ne deriva ha, oltre all'intercetta, 2 parametri (numero di PC considerate) invece che 4. Vediamo se, con più esplicative, il modello si adatta meglio ai dati
win.prob.glm.0 <- glm(cbind(W, L) ~ eFG. + TOV. + ORB. + FTR,
family = binomial, data = data)
summary(win.prob.glm.0)
# Il modello appena costruito fornisce un adattamento migliore ai dati rispetto a quello visto in precedenza
compare.matrix <- matrix(data = c(win.prob.glm.pca$aic, win.prob.glm.0$aic,
BIC(win.prob.glm.pca), BIC(win.prob.glm.0)), nrow = 2, byrow = TRUE)
colnames(compare.matrix) <- c("PCA", "4Factors")
row.names(compare.matrix) <- c("AIC", "BIC")
compare.matrix
# Anche qui confrontiamo valori osservati e predetti
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm.0), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# L'adattamento è visibilmente migliorato, tuttavia non siamo soddisfatti rispetto a ciò che otteniamo con il modello saturo
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm.0$deviance, win.prob.glm.0$df.residual, lower.tail = FALSE)
data
# Considerata l'importanza che hanno il tiro da tre punti e il pace (ritmo di gioco) nel basket moderno costruiamo un nuovo modello aggiungendo 3 esplicative: numero di tiri da tre segnati, numero di tiri da tre tentati e possessi per partita
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
data
# Considerata l'importanza che hanno il tiro da tre punti e il pace (ritmo di gioco) nel basket moderno costruiamo un nuovo modello aggiungendo 3 esplicative: numero di tiri da tre segnati, numero di tiri da tre tentati e possessi per partita
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
# Il coefficiente relativo ai tiri da tre punti tentati a partita è non significativo. Aggiorniamo il modello
win.prob.glm <- update(win.prob.glm, . ~ . - FG3A.GP)
summary(win.prob.glm)
exp(-4)
exp(-4) / (1 + exp(-4))
# Considerata l'importanza che hanno il tiro da tre punti e il pace (ritmo di gioco) nel basket moderno costruiamo un nuovo modello aggiungendo 3 esplicative: numero di tiri da tre segnati, numero di tiri da tre tentati e possessi per partita
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
# Il coefficiente relativo ai tiri da tre punti tentati a partita è non significativo. Aggiorniamo il modello
win.prob.glm <- update(win.prob.glm, . ~ . - FG3A.GP)
summary(win.prob.glm)
# L'intercetta risulta non significativa
win.prob.glm <- update(win.prob.glm, . ~ . - 1)
summary(win.prob.glm)
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm)))
colnames(compare.matrix) <- c("PCA", "4Factors", "4Factors + 3PTShot")
compare.matrix
# Accettiamo l'ipotesi nulla ad un livello di significatività del 5%
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
# Grafico valori previsti e osservati
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# Media della discrepanza tra il numero di vittorie effettivo e il numero di vittorie stimato
mean(abs(residuals(win.prob.glm, type = "response"))) * 82
# Metodo alternativo
mean(abs(data$W - fitted(win.prob.glm) * 82))
sd(abs(data$W - fitted(win.prob.glm) * 82))
# Ciò significa che in media sbaglio la previsione delle vittorie di 4 unità
# Non vi è struttura di dipendenza tra i valori predetti e i residui
plot(win.prob.glm, which = 1)
# Le possibili interazioni aggiuntive non sono significative
add1(win.prob.glm, . ~ . + (.)^2, test = "Chisq")
# f)
sleep.gee <- gee(y ~ day + trt, id = case, family = gaussian,
corstr = "independence", data = Sleep1)
# f)
library(gee)
sleep.gee <- gee(y ~ day + trt, id = case, family = gaussian,
corstr = "independence", data = Sleep1)
rm(list = ls())
# Esercizio 2
head(Sleep, 10)
load("/Users/garbooo/Downloads/dati_esame_m2.RData")
# Esercizio 2
head(Sleep, 10)
# a)
str(Sleep)
# unità statistica: maschio adulto che ha preso parte all'esperimento
# day0, day1, day2, day3: indice di di deficit di vigilanza misurato in
#                         giorni successivi; variabile risposta;
#                         variabile quantitativa continua
# trat: gruppo di trattamento; variabile qualitativa nominale;
#       variabile concomitante
# b)
# traiettorie individuali
day <- 0:3
with(Trauma, {
plot(day, c(0, 10, 20, 40), type = "n", xlab = "day",
ylab = "indice di deficit di vigilanza",
main = "Traiettorie individuali")
for(i in 1:13) lines(day, Sleep[i, 3:6])
for(i in 14:26) lines(day, Sleep[i, 3:6], col = 2, lty = 2)
legend("topleft", c("treat = 1", "treat = 2"), col = c(1, 2), lty = c(1, 2))
})
# traiettorie medie
mean1 <- apply(Sleep[Sleep$treat == 1, 3:6], 2, mean)
mean2 <- apply(Sleep[Sleep$treat == 2, 3:6], 2, mean)
with(Trauma, {
plot(day, c(0, 10, 20, 40), type = "n", xlab = "day",
ylab = "indice di deficit di vigilanza",
main = "Traiettorie dei gruppi")
lines(day, mean1)
lines(day, mean2, col = 2, lty = 2)
legend("topleft", c("treat = 1", "treat = 2"), col = c(1, 2), lty = c(1, 2))
})
# In generale, il gruppo a cui è stato somministrato un placebo
# meno deficit di vigilanza rispetto all'altro gruppo. Appare ragionevole
# ipotizzare che l'indice di vigilanza vari linearmente con il tempo
head(Sleep1, 10)
# Sleep1 è il formato lungo del dataframe Sleep: le osservazioni
# relative allo stesso paziente sono riportate in ordine una sotto l'altra
library(lattice)
xyplot(y ~ day| as.factor(case), group = as.factor(trt), data = Sleep1)
# c) d)
Sleep1$trt <- as.factor(Sleep1$trt)
# Modello lineare normale
sleep.mln <- lm(y ~ day + trt, data = Sleep1)
summary(sleep.mln)
# Modello con interazioni
sleep.mln.int <- lm(y ~ day * trt, data = Sleep1)
summary(sleep.mln.int)
# Linterazione è non significativa
# Modello con termine quadratico
sleep.mln.quad <- lm(y ~ day + trt + I(day^2), data = Sleep1)
summary(sleep.mln.quad)
# Il coefficiente del termine quadratico è non significativo
# In tutti e tre i casi l'adattamento non è molto buono
# e)
# Intervallo di confidenza per la media
ic.mean <- predict(sleep.mln, newdata = data.frame(day = 4, trt = "2"),
level = 0.95, interval = "confidence")
# Intervallo di confidenza per la risposta
ic.ans <- predict(sleep.mln, newdata = data.frame(day = 4, trt = "2"),
level = 0.95, interval = "prediction")
ic.mean
ic.ans
# f)
library(gee)
sleep.gee <- gee(y ~ day + trt, id = case, family = gaussian,
corstr = "independence", data = Sleep1)
summary(sleep.gee)
# f)
library(geepack)
sleep.gee <- geeglm(y ~ day + trt, id = case, family = gaussian,
corstr = "independence", data = Sleep1)
summary(sleep.gee)
sleep.gee.ind <- geeglm(y ~ day + trt, id = case, family = gaussian,
corstr = "independence", data = Sleep1)
summary(sleep.gee)
# f)
library(gee)
Sleep.gee.ind <- gee(y ~ trt * day, id = case, family= gaussian,
8
corstr ="independence", data=Sleep1)
Sleep.gee.ind <- gee(y ~ trt * day, id = case, family= gaussian,
corstr ="independence", data=Sleep1)
summary(Sleep.gee.ind)
Sleep.gee.ind1 <- gee(y ~ trt + day, id = case, family= gaussian,
corstr ="independence", data=Sleep1)
summary(Sleep.gee.ind1)
Sleep.gee.ind2 <- gee(y ~ trt + day +I(day^2), id = case, family= gaussian,
corstr ="independence", data=Sleep1)
summary(Sleep.gee.ind2)
#
Sleep.gee.exch <- gee(y  ~ trt*day, id = case, family= gaussian,
corstr ="exchangeable", data=Sleep1)
summary(Sleep.gee.exch)
Sleep.gee.exch1 <- gee(y  ~ trt + day, id = case, family= gaussian,
corstr ="exchangeable", data=Sleep1)
summary(Sleep.gee.exch1)
Sleep.gee.exch2 <- gee(y  ~ trt + day +I(day^2), id = case, family= gaussian,
corstr ="exchangeable", data=Sleep1)
summary(Sleep.gee.exch2)
#
Sleep.gee.ar1 <- gee(y ~ trt*day, id = case, family= gaussian,
corstr ="AR-M", Mv=1,  data=Sleep1)
summary(Sleep.gee.ar1)
Sleep.gee.ar1.1 <- gee(y  ~ trt + day, id = case,  family= gaussian,
corstr ="AR-M", Mv=1,data=Sleep1)
summary(Sleep.gee.ar1.1)
Sleep.gee.ar1.2 <- gee(y  ~ trt + day +I(day^2), id = case,  family= gaussian,
corstr ="AR-M", Mv=1, data=Sleep1)
summary(Sleep.gee.ar1.2)
#
Sleep.gee.u <- gee(y  ~ trt*day, id = case, family= gaussian,
corstr ="unstructured", data=Sleep1)
summary(Sleep.gee.u)
Sleep.gee.u1 <- gee(y  ~ trt + day, id = case,  family= gaussian,
corstr ="unstructured", data=Sleep1)
summary(Sleep.gee.u1)
Sleep.gee.u2 <- gee(y  ~ trt + day +I(day^2), id = case,  family= gaussian,
corstr ="unstructured", data=Sleep1)
summary(Sleep.gee.u2)
Sleep1
# h) i)
library(nlme)
Sleep.lme <- lme( y ~ trt + day, random = ~1 | case, data=Sleep1)
summary(Sleep.lme)
# modello con intercetta casuale ma con errori non indipendenti (ar1)
Sleep.lme1 <- lme(y ~ trt + day, random = ~1 | case,
correlation = corAR1(form= ~1| case), data=Sleep1)
summary(Sleep.lme1)
anova(Sleep.lme, Sleep.lme1)
Sleep.lme1.1 <- lme(y ~ trt + day +I(day^2), random = ~1 | case,
correlation = corAR1(form= ~1| case), data=Sleep1)
summary(Sleep.lme1.1)
# pendenze casuali
Sleep.lme2 <- lme( y ~ trt + day, random = ~1 + day | case,
method= "ML", data=Sleep1)
summary(Sleep.lme2)
Sleep.lme.ml <- lme( y ~ trt + day, random = ~1 | case, method="ML", data=Sleep1)
anova(Sleep.lme.ml, Sleep.lme2)
# stime BLUP degli effetti casuali t(ranef(Sleep.lme)) t(ranef(Sleep.lme1)) t(ranef(Sleep.lme2))
AIC(Sleep.lme)
AIC(Sleep.lme1)
AIC(Sleep.lme1.1)
AIC(Sleep.lme2)
# stime BLUP degli effetti casuali t(ranef(Sleep.lme)) t(ranef(Sleep.lme1)) t(ranef(Sleep.lme2))
AIC(Sleep.lme)
AIC(Sleep.lme1)
AIC(Sleep.lme1.1)
AIC(Sleep.lme2)
# stime BLUP degli effetti casuali
t(ranef(Sleep.lme))
t(ranef(Sleep.lme1))
t(ranef(Sleep.lme2))
summary(Sleep.lme1)
