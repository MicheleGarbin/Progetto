summary(mod.gee1)
mod.nb <- glm.nb(y ~ lage + lbase + trt + lbase:trt,data = epil)
summary(mod.nb)
mod.gee1 <- gee(y ~ lage + period+ lbase + trt +lbase:trt,id = subject,
data = epil,family = poisson,corstr = 'exchangeable')
summary(mod.gee1)
mod.gee2 <- gee(y ~ lage + period + lbase + trt +lbase:trt,id = subject,
data = epil,family = poisson,corstr = 'AR-M',Mv = 1)
summary(mod.gee2)
pnorm(-1.942919)
student.glmer <- glmer(y ~ item + (1 | subject), data = Testingresso,
family = binomial, nAGQ = 70)
summary(student.glmer)
par(mfrow = c(1, 2))
# dati previsti dal modello
xyplot(fitted(student.glmer) ~ item | as.factor(subject), data = Testingresso)
# dati osservati
xyplot(y ~ item | as.factor(subject), data = Testingresso)
par(mfrow = c(1, 1))
par(mfrow = c(1, 2))
# dati previsti dal modello
xyplot(fitted(student.glmer) ~ item | as.factor(subject), data = Testingresso)
# dati osservati
xyplot(y ~ item | as.factor(subject), data = Testingresso)
# dati previsti dal modello
xyplot(fitted(student.glmer) ~ item | as.factor(subject), data = Testingresso)
# dati osservati
xyplot(y ~ item | as.factor(subject), data = Testingresso)
summary(student.glmer)
# (a) Come analisi preliminare si valutino le percentuali di risposte
# corrette per soggetto e per domanda
prop.table(table(Testingresso$subject, Testingresso$y), 1)[, 2] * 100
prop.table(table(Testingresso$item, Testingresso$y), 1)[, 2] * 100
# confronto risposte corrette attese per domanda con quelle osservate
cbind(prop.table(table(Testingresso$item, fitted(student.glmer)), 1)[, 2] * 100, prop.table(table(Testingresso$item, Testingresso$y), 1)[, 2] * 100)
dim(fitted(student.glmer))
length(fitted(student.glmer))
table(Testingresso$item, fitted(student.glmer))
cbind(prop.table(table(Testingresso$item, freq.exp), 1)[, 2] * 100, prop.table(table(Testingresso$item, Testingresso$y), 1)[, 2] * 100)
# confronto risposte corrette attese per domanda con quelle osservate
freq.exp <- ifelse(fitted(student.glmer) > 0.5, 1, 0)
cbind(prop.table(table(Testingresso$item, freq.exp), 1)[, 2] * 100, prop.table(table(Testingresso$item, Testingresso$y), 1)[, 2] * 100)
# le percentuali attese e osservate differiscono di un 10 per cento per
# quasi tutte le domande
# confronto percentuale di risposte corrette per soccetto attese vs osservate
cbind(prop.table(table(Testingresso$subject, freq.exp), 1)[, 2] * 100, prop.table(table(Testingresso$subject, Testingresso$y), 1)[, 2] * 100)
rm(list = ls())
1.83^2 / (1.83^2 + 1.37^2)
load(file.choose())
head(Minatore, 10)
table(Minatore$y)
length(Minatore)
dim(Minatore)
# a)
str(Minatore)
table(Minatore$area)
options(digits = 5)
# b)
with(Minatore, plot(legname, y))
# b)
table(Minatore$y)
# L'osservazione anomala è quella per cui y = 19
Minatore[Minatore$y == 19]
# L'osservazione anomala è quella per cui y = 19
Minatore[Minatore$y == 19,]
# Rimuovo l'osservazione anomala
data <- Minatore[-11, ]
# b)
with(Minatore, plot(legname, y))
table(Minatore$y)
# L'osservazione anomala è quella per cui y = 19
Minatore[Minatore$y == 19,]
# Costruisco un dataframe senza l'osservazione anomala
M1 <- Minatore[-11, ]
with(Minatore, plot(buloke, y))
with(Minatore, plot(area, y))
with(Minatore, plot(eucal, y))
with(Minatore, table(cespugli, y))
with(Minatore, prop.table(table(cespugli, y), 1))
plot(1:10, cespugli.rel[1, ], type = "l")
with(Minatore, plot(eucal, y))
cespugli.rel <- with(Minatore, prop.table(table(cespugli, y), 1))
plot(1:10, cespugli.rel[1, ], type = "l")
plot(1:10, cespugli.rel[1, ], type = "l", ylab = "frequenze relative osservate",
xlab = "")
lines(1:10, cespugli.rel[2, ], type = "l", col = 2, lty = 2)
with(Minatore, boxplot(cespugli, y))
with(Minatore, tapply(y, cespugli, mean))
with(Minatore, plot(legname, y))
with(Minatore, plot(buloke, y))
with(Minatore, plot(area, y))
with(Minatore, plot(eucal, y))
# La distribuzione della risposta appare diversa tra i gruppi
# individuati dalla variabile cespugli
with(Minatore, boxplot(pascolo, y))
# Fino a qua l'esplicativa considerata non sembra spiegare
# molto della variabilità della risposta
with(Minatore, boxplot(cespugli, y))
# La distribuzione della risposta appare diversa tra i gruppi
# individuati dalla variabile cespugli
with(Minatore, boxplot(pascolo, y))
# Fino a qua l'esplicativa considerata non sembra spiegare
# molto della variabilità della risposta
with(Minatore, boxplot(cespugli, y))
# La distribuzione della risposta appare diversa tra i gruppi
# individuati dalla variabile cespugli
with(Minatore, boxplot(pascolo, y))
Minatore
# Fino a qua l'esplicativa considerata non sembra spiegare
# molto della variabilità della risposta
with(Minatore, boxplot(cespugli, y))
# La distribuzione della risposta appare diversa tra i gruppi
# individuati dalla variabile cespugli
with(Minatore, boxplot(pascolo, y))
# a)
str(Minatore)
# Fino a qua l'esplicativa considerata non sembra spiegare
# molto della variabilità della risposta
with(Minatore, boxplot(cespugli, y))
with(Minatore, tapply(y, cespugli, mean))
# La distribuzione della risposta appare diversa tra i gruppi
# individuati dalla variabile cespugli
with(Minatore, boxplot(pascolo, y))
# La distribuzione della risposta appare diversa tra i gruppi
# individuati dalla variabile cespugli
with(Minatore, boxplot(pascolo, y))
# Fino a qua l'esplicativa considerata non sembra spiegare
# molto della variabilità della risposta
with(Minatore, boxplot(y ~ cespugli))
# Fino a qua l'esplicativa considerata non sembra spiegare
# molto della variabilità della risposta
with(Minatore, boxplot(y ~ cespugli))
with(Minatore, tapply(y, cespugli, mean))
# La distribuzione della risposta appare diversa tra i gruppi
# individuati dalla variabile cespugli
with(Minatore, boxplot(y ~ pascolo))
with(Minatore, tapply(y, pascolo, mean))
with(Minatore, plot(eucal, y))
with(Minatore, plot(area, y))
# b)
with(Minatore, table(y))
with(Minatore, plot(table(y)))
mean(Minatore$y)
var(Minatore$y)
boxplot(Minatore$y)
which(Minatore$y>15)
M1 <- Minatore[-c(11),] mean(M1$y)
var(M1$y)
with(M1, plot(table(y)))
# b)
with(Minatore, table(y))
with(Minatore, plot(table(y)))
mean(Minatore$y)
var(Minatore$y)
boxplot(Minatore$y)
# L'osservazione anomala è quella per cui y = 19
Minatore[Minatore$y == 19,]
# Costruisco un dataframe senza l'osservazione anomala
M1 <- Minatore[-11, ]
var(M1$y)
with(M1, plot(table(y)))
#
with(Minatore, plot(legname, y))
with(Minatore, plot(buloke, y))
with(Minatore, plot(area, y))
with(Minatore, plot(eucal, y))
with(Minatore, boxplot(y ~ cespugli))
with(Minatore, tapply(y, cespugli, mean))
with(Minatore, boxplot(y ~ pascolo))
with(Minatore, tapply(y, pascolo, mean))
# Modello di poisson con legame canonico (logaritmo
# c) d)
# Modello di poisson con legame canonico (logaritmo)
minatore.glm <- glm(y ~ ., family = poisson, data = Minatore)
summary(minatore.glm)
drop1(minatore.glm, test = "Chisq")
minatore.glm <- update(minatore.glm, . ~ . -cespugli)
drop1(minatore.glm, test = "Chisq")
minatore.glm <- update(minatore.glm, . ~ . -pascolo)
drop1(minatore.glm, test = "Chisq")
minatore.glm <- update(minatore.glm, . ~ . -buloke)
drop1(minatore.glm, test = "Chisq")
minatore.glm <- update(minatore.glm, . ~ . -legname)
drop1(minatore.glm, test = "Chisq")
drop1(minatore.glm, test = "Chisq")
significative, provo ad aggiungere
# Ora che ho solo variabili significative, provo ad aggiungere
# un termine di interazione
add1(minatore.glm, . ~ . + area:eucal, test = "Chisq")
summar(minatore.glm)
summary(minatore.glm)
head(Minatore, 10)
Minatore
# L'interazione risulta non significativa: il modello finale
# che scelgo ha come esplicative eucal e area
summary(minatore.glm)
fitted(minatore.glm)
# e)
# Non posso valutare la bontà di adattamento del modello guardando la devianza
# residua poichè le medie attese non sono sufficientemente elevate
obs <- prop.table(table(Minatore$y))[1:9]
obs
poi.exp <- sapply(0:8, function(x) dpois(x, fitted(minatore.glm)))
comp.fr <- cbind(obs, poi.exp)
# e)
# Non posso valutare la bontà di adattamento del modello guardando la devianza
# residua poichè le medie attese non sono sufficientemente elevate
obs <- prop.table(table(Minatore$y))[1:9]
poi.exp <- sapply(0:8, function(x) dpois(x, fitted(minatore.glm)))
poi.exp
poi.exp <- sapply(0:8, function(x) mean(dpois(x, fitted(minatore.glm))))
comp.fr <- cbind(obs, poi.exp)
comp.fr
# L'interazione risulta non significativa: il modello finale
# che scelgo ha come esplicative eucal e area
summary(minatore.glm)
sum(residuals(minatore.glm, type = "Pearson")^2)
sum(residuals(minatore.glm, type = "pearson")^2)
# e)
# Non posso valutare la bontà di adattamento del modello guardando la devianza
# residua poichè le medie attese non sono sufficientemente elevate
# bontà di adattamento
par(mfrow = c(2, 2))
plot(minatore.glm, which = 1:4)
# Frequenze relative attese vs frequenze relative osservate
obs <- prop.table(table(Minatore$y))[1:9]
poi.exp <- sapply(0:8, function(x) mean(dpois(x, fitted(minatore.glm))))
comp.fr <- cbind(obs, poi.exp)
comp.fr
1 - pchisq(X2,28 )
X2 <- sum(residuals(minatore.glm4, type="pearson")^2)
X2
X2 <- sum(residuals(minatore.glm, type = "pearson") ^2)
X2
1 - pchisq(X2,28 )
# L'interazione risulta non significativa: il modello finale
# che scelgo ha come esplicative eucal e area
summary(minatore.glm)
library(MLGdata)
head(Homicide)
str(Homicide)
table(Homicide)
p.table <- prop.table(table(Homicide),margin = 1)
p.table
Homicide$race <- as.factor(Homicide$race)
mod.pois <- glm(count~race,family = poisson,data = Homicide)
summary(mod.pois)
#riportando in scala esponenziale:
#per un nero il valore atteso di omicidio in un anno è stimato essere
exp(mod.pois$coefficients)[2]
#ic per il valore(senza usare il metodo delta, ma giusto per un'idea):
exp(1.73314 + c(-1,1)*qnorm(0.975)*0.14657)
summary(mod.pois)
tab.b.agg <- cbind(c(table(Homicide)[1,1:3],sum(table(Homicide)[1,4:7])),
c(fr.att.bianchi[1:3],sum(fr.att.bianchi[4:7])))
tab.n.agg <- cbind(c(table(Homicide)[2,1:4],sum(table(Homicide)[2,5:7])),
c(fr.att.neri[1:4],sum(fr.att.neri[5:7])))
tab <- rbind(tab.b.agg,tab.n.agg)
Homicide$race <- as.factor(Homicide$race)
mod.pois <- glm(count~race,family = poisson,data = Homicide)
summary(mod.pois)
#riportando in scala esponenziale:
#per un nero il valore atteso di omicidio in un anno è stimato essere
exp(mod.pois$coefficients)[2]
#ic per il valore(senza usare il metodo delta, ma giusto per un'idea):
exp(1.73314 + c(-1,1)*qnorm(0.975)*0.14657)
#valore atteso di accoltellamenti per bianchi e neri:
mu <- unique(fitted(mod.pois))
mu
#b
nb <- sum(table(Homicide)[1,])
nn <- sum(table(Homicide)[2,])
fr.att.bianchi <- dpois(0:6,mu[1]) * nb
fr.att.neri <- dpois(0:6,mu[2]) * nn
#confornto per i bianchi:
cbind(table(Homicide)[1,],round(fr.att.bianchi,3))
#confronto per i neri:
cbind(table(Homicide)[2,],round(fr.att.neri,3))
tab.b.agg <- cbind(c(table(Homicide)[1,1:3],sum(table(Homicide)[1,4:7])),
c(fr.att.bianchi[1:3],sum(fr.att.bianchi[4:7])))
tab.n.agg <- cbind(c(table(Homicide)[2,1:4],sum(table(Homicide)[2,5:7])),
c(fr.att.neri[1:4],sum(fr.att.neri[5:7])))
tab <- rbind(tab.b.agg,tab.n.agg)
tab
#calcoliamo la statistica di pearson:
tab <- as.matrix(tab)
head(Homicide, 10)
# f)
library(MASS)
minatore.nbin <- glm.nb(y ~ eucal, data = Ants)
minatore.nbin <- glm.nb(y ~ eucal, data = Minatore)
minatore.nbin
# f)
library(MASS)
minatore.nbin <- glm.nb(y ~ eucal, data = Minatore)
minatore.nbin <- glm.nb(y ~ eucal, data = Minatore)
add1(minatore.nbin, . ~ . + area + pascolo + cespugli + buloke + legname,
test = "Chisq")
# Nessuna variabile tra quelle indicate nell'add1 risulta
# significativa quando aggiunta
summary(minatore.nbin)
minatore.nbin$theta
?dnbinom
# E' confermata la presenza di sovradispersione (nel GLM poisson theta
# dovrebbe valere 1)
nbin.exp <- sapply(0:8, function(x) mean(dnbinom(x, mu = fitted(minatore.nbin),
size = minatore.nbin$theta)))
comp.fr <- cbind(comp.fr, nbin.exp)
comp.fr
# g)
minatore.ql <- glm(y ~., family=quasipoisson, data=Minatore)
summary(minatore.ql)
minatore.ql0 <- glm(y ~ eucal, family=quasipoisson, data=Minatore)
summary(minatore.ql0)
minatore.ql1 <- glm(y ~ eucal + area, family=quasipoisson, data=Minatore)
summary(minatore.ql1)
anova(minatore.ql0, minatore.ql, test="Chisq")
minatore.ql0 <- glm(y ~ eucal, family=quasipoisson, data=Minatore)
summary(minatore.ql0)
minatore.nbin <- glm.nb(y ~ eucal, data = Minatore)
# Nessuna variabile tra quelle indicate nell'add1 risulta
# significativa quando aggiunta
summary(minatore.nbin)
minatore.nbin$theta
coef(minatore.nbin, minatore.ql0)
c(coef(minatore.nbin), coef(minatore.ql0))
minatore.nbin <- glm.nb(y ~ eucal, data = Minatore)
add1(minatore.nbin, . ~ . + area + pascolo + cespugli + buloke + legname,
test = "Chisq")
# Nessuna variabile tra quelle indicate nell'add1 risulta
# significativa quando aggiunta
summary(minatore.nbin)
minatore.nbin$theta
summary(minatore.ql0)
minatore.zi.poi <- zeroinfl(y ~ ., data = Minatore)
# h)
library(pscl)
minatore.zi.poi <- zeroinfl(y ~ ., data = Minatore)
minatore.zi.poi <- zeroinfl(y ~ 1, data = Minatore)
minatore.zi.poi <- zeroinfl(y ~ ., data = Minatore)
summary(minatore.zi.poi)
minatore.zi.poi <- zeroinfl(y ~ eucal + area, data = Minatore)
summary(minatore.zi.poi)
minatore.zi.poi.full <- zeroinfl(y ~ ., data = Minatore)
Wp <- 2 * (loglik(minatore.zi.poi.full) - loglik(minatore.zi.poi))
Wp <- 2 * (minatore.zi.poi.full$loglik - minatore.zi.poi$loglik)
minatore.zi.poi.full <- zeroinfl(y ~ ., data = Minatore)
minatore.zi.poi <- zeroinfl(y ~ eucal + area, data = Minatore)
summary(minatore.zi.poi)
pchisq(Wp, 14 - 6, lower.tail = FALSE)
minatore.zi.poi.2 <- zeroinfl(eucal, data = Minatore)
minatore.zi.poi.2 <- zeroinfl(y ~ eucal, data = Minatore)
summary(minatore.zi.poi.2)
# E' preferibile il modello con esplicative eucal e area rispetto
# al modello con tutte le esplicative possibili
minatore.zi.poi.2 <- zeroinfl(y ~ eucal, data = Minatore)
summary(minatore.zi.poi.2)
pchisq(Wp, 6 - 4, lower.tail = FALSE)
splicative eucal e area in termini di
# E' preferibile il modello con esplicative eucal e area in termini di
# log - caduta di verosimiglianza
minatore.zi.poi.3 <- zeroinf(y ~ eucal + area | eucal, data = Minatore)
# E' preferibile il modello con esplicative eucal e area in termini di
# log - caduta di verosimiglianza
minatore.zi.poi.3 <- zeroinfl(y ~ eucal + area | eucal, data = Minatore)
summary(minatore.zi.poi.3)
curve(exp(x) / (1 + exp(x)))
par(mfrow = c(1, 1))
curve(exp(x) / (1 + exp(x)))
fr.0 <- cphihat + phihat * mean(dpois(0, fitted(minatore.zi.poi.3)))
cphihat <- plogis(co[p+1]+co[p+2]*Minatore$eucal)
phihat <- 1 - cphihat
#
co <- coef(minatore.zi.poi.3)
p <- ncol(model.matrix(minatore.zi.poi.3))
muhat <- as.vector(exp(model.matrix(minatore.zi.poi.3)%*%co[1:p]))
cphihat <- plogis(co[p+1]+co[p+2]*Minatore$eucal)
phihat <- 1 - cphihat
fr.0 <- cphihat + phihat * mean(dpois(0, fitted(minatore.zi.poi.3)))
fr.0 <- cphihat + phihat * mean(dpois(0, fitted(minatore.zi.poi.3)))
fr.1 <- phihat * sapply(1:8, function(x) mean(dpois(x, fitted(minatore.zi.poi.3))))
zi.poi.exp <- sapply(0:8, function(x) mean(phihat * dpois(x, fitted(minatore.zi.poi.3))))
zi.poi.exp[1] <- zi.poi.exp[1] + mean(cphihat)
comp.fr
zi.poi.exp <- sapply(0:8, function(x) mean(phihat * dpois(x, fitted(minatore.zi.poi.3))))
zi.poi.exp[1] <- zi.poi.exp[1] + mean(cphihat)
comp.fr <- cbind(comp.fr, zi.poi.exp)
comp.fr
# E' preferibile il modello con esplicative eucal e area in termini di
# log - caduta di verosimiglianza
minatore.zi.poi.3 <- zeroinfl(y ~ eucal + area | eucal, data = Minatore)
summary(minatore.zi.poi.3)
comp.fr <- cbind(comp.fr, ZINB.exp)
# i)
minatore.ZINB <- zeroinfl(y~ eucal+area,dist="negbin",  data=Minatore)
summary(minatore.ZINB)
minatore.ZINB1 <- zeroinfl(y~ eucal+area|eucal,dist="negbin",  data=Minatore)
summary(minatore.ZINB1)
AIC(minatore.ZINB1)
#
co <- coef(minatore.ZINB1)
p <- ncol(model.matrix(minatore.ZINB1))
muhat <- as.vector(exp(model.matrix(minatore.ZINB1)%*%co[1:p]))
cphihat <- plogis(co[p+1]+co[p+2]*Minatore$eucal)
phihat <- 1- cphihat
thetahat <- minatore.ZINB1$theta
ZINB.exp <- sapply(0:8, function(x) mean(phihat*dnbinom(x, m=muhat, size=thetahat))) ZINB.exp[1] <- ZINB.exp[1] + mean(cphihat)
comp.fr <- cbind(comp.fr, ZINB.exp)
# i)
minatore.ZINB <- zeroinfl(y~ eucal+area,dist="negbin",  data=Minatore)
summary(minatore.ZINB)
minatore.ZINB1 <- zeroinfl(y~ eucal+area|eucal,dist="negbin",  data=Minatore)
summary(minatore.ZINB1)
AIC(minatore.ZINB1)
#
co <- coef(minatore.ZINB1)
p <- ncol(model.matrix(minatore.ZINB1))
muhat <- as.vector(exp(model.matrix(minatore.ZINB1)%*%co[1:p]))
cphihat <- plogis(co[p+1]+co[p+2]*Minatore$eucal)
phihat <- 1- cphihat
thetahat <- minatore.ZINB1$theta
ZINB.exp <- sapply(0:8, function(x) mean(phihat*dnbinom(x, m=muhat, size=thetahat))) ZINB.exp[1] <- ZINB.exp[1] + mean(cphihat)
ZINB.exp <- sapply(0:8, function(x) mean(phihat*dnbinom(x, m=muhat, size=thetahat)))
ZINB.exp[1] <- ZINB.exp[1] + mean(cphihat)
comp.fr <- cbind(comp.fr, ZINB.exp)
comp.fr
setwd("~/Desktop/TERZO ANNO/SDE2/Progetto_prova")
# Per cominciare, carichiamo i dati
data <- read.table("data/team_stats.txt", header = T)
head(data)
# Come primo modello consideriamo come esplicative le componenti principali derivanti dai 4 fattori
apply(data[, 6:9], 2, sd)
# La percentuale di palle perse ha una varianza molto diversa dalle altre metriche. E' necessario standardizzare i dati
pca <- prcomp(data[, 6:9], scale. = TRUE)
# Guardiamo la percentuale di varianza spiegata cumulata per capire quante componenti utilizzare
cumsum((pca$sdev ^ 2) / sum(pca$sdev ^ 2))
# 2 componenti principali spiegano una il 74% della varianza totale
X.0 <- pca$x[, c(1, 2)]
# Ora che ho ricavato le esplicative, posso procedere con la costruzione del modello
win.prob.glm.pca <- glm(cbind(data[, 1], data[, 2]) ~ X.0[, 1] + X.0[, 2], family = binomial)
summary(win.prob.glm.pca)
# Il coefficiente della seconda variabile canonica è non significativo. Anche l'intercetta risulta non significativa, con il relativo coefficiente sostanzialmente degenere in 0. Aggiorniamo il modello
win.prob.glm.pca <- update(win.prob.glm.pca, . ~ . - X.0[, 2])
summary(win.prob.glm.pca)
# Guardando la devianza residua non siamo soddisfatti dell'adattamento del modello. Il modello corrente, con soli 2 parametri in più rispetto al modello nullo, spiega molto di più di quest'ultimo. Tuttavia viene rifiutata l'ipotesi di adattamento del modello corrente rispetto a quello nullo
# H0: modello nullo   H1: modello corrente
pchisq(win.prob.glm.pca$null.deviance - win.prob.glm.pca$deviance,
win.prob.glm.pca$df.null - win.prob.glm.pca$df.residual, lower.tail = FALSE)
# H0 : modello corrente  H1: modello saturo
pchisq(win.prob.glm.pca$deviance, win.prob.glm.pca$df.residual, lower.tail = FALSE)
# Compariamo i valori osservati con i valori previsti dal modello. L'asse x indica le squadre in ordine alfabetico
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors (PCA)")
points(1:30, fitted(win.prob.glm.pca), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# Costruiamo un altro modello prendendo come esplicative i 4 fattori senza applicare la PCA. La PCA comporta infatti una riduzione della dimensionalità: il modello che ne deriva ha, oltre all'intercetta, 2 parametri (numero di PC considerate) invece che 4. Vediamo se, con più esplicative, il modello si adatta meglio ai dati
win.prob.glm.0 <- glm(cbind(W, L) ~ eFG. + TOV. + ORB. + FTR,
family = binomial, data = data)
summary(win.prob.glm.0)
# Il modello appena costruito fornisce un adattamento migliore ai dati rispetto a quello visto in precedenza
compare.matrix <- matrix(data = c(win.prob.glm.pca$aic, win.prob.glm.0$aic,
BIC(win.prob.glm.pca), BIC(win.prob.glm.0)), nrow = 2, byrow = TRUE)
colnames(compare.matrix) <- c("PCA", "4Factors")
row.names(compare.matrix) <- c("AIC", "BIC")
compare.matrix
# Anche qui confrontiamo valori osservati e predetti
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm.0), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# L'adattamento è visibilmente migliorato, tuttavia non siamo soddisfatti rispetto a ciò che otteniamo con il modello saturo
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm.0$deviance, win.prob.glm.0$df.residual, lower.tail = FALSE)
# Considerata l'importanza che hanno il tiro da tre punti e il pace (ritmo di gioco) nel basket moderno costruiamo un nuovo modello aggiungendo 3 esplicative: numero di tiri da tre segnati, numero di tiri da tre tentati e possessi per partita
win.prob.glm <- glm(cbind(W, L) ~ ., family = binomial, data = data)
summary(win.prob.glm)
# Il coefficiente relativo ai tiri da tre punti tentati a partita è non significativo. Aggiorniamo il modello
win.prob.glm <- update(win.prob.glm, . ~ . - FG3A.GP)
summary(win.prob.glm)
# L'intercetta risulta non significativa
win.prob.glm <- update(win.prob.glm, . ~ . - 1)
summary(win.prob.glm)
# L'adattamento rispetto ai modelli precedenti è migliorato
compare.matrix <- cbind(compare.matrix, c(win.prob.glm$aic, BIC(win.prob.glm)))
colnames(compare.matrix) <- c("PCA", "4Factors", "4Factors + 3PTShot")
compare.matrix
# Accettiamo l'ipotesi nulla ad un livello di significatività del 5%
# H0: modello corrente   H1: modello saturo
pchisq(win.prob.glm$deviance, win.prob.glm$df.residual, lower.tail = FALSE)
# Grafico valori previsti e osservati
with(data,{
plot(1:30, W / 82, pch = 20,
xlab = "", xaxt = "n", ylab = "RS WIN%",
main = "Valori predetti dai four factors")
points(1:30, fitted(win.prob.glm), pch = 7, col = 2)
legend("topright", legend = c("Valori osservati", "Valori previsti"),
col = c(1, 2), pch = c(20, 7))
})
# Media della discrepanza tra il numero di vittorie effettivo e il numero di vittorie stimato
mean(abs(residuals(win.prob.glm, type = "response"))) * 82
# Metodo alternativo
mean(abs(data$W - fitted(win.prob.glm) * 82))
sd(abs(data$W - fitted(win.prob.glm) * 82))
summary(win.prob.glm)
